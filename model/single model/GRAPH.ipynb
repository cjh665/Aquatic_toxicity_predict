{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e554240-2efc-4d7b-9dab-68cabc7eece8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图数据将保存到: /root/Invertebrates_EC50_multi_fusion/graph/graph_outputs/Invertebrates_EC50_graphs.pt\n",
      "row_id 将保存到: /root/Invertebrates_EC50_multi_fusion/graph/graph_outputs/row_id_graph.npy\n",
      "图嵌入将保存到: /root/Invertebrates_EC50_multi_fusion/graph/graph_outputs/reg_graph_embeddings.npy\n",
      "数据行数: 3620\n",
      "   row_id    SMILES_Canonical_RDKit  mgperL_log  Duration_Value(hour) Effect  \\\n",
      "0       0        [Cl-].[Cl-].[Zn+2]    0.113943                  96.0    ITX   \n",
      "1       1  O=S(=O)([O-])[O-].[Zn+2]    0.397940                  24.0    ITX   \n",
      "2       2        [Cl-].[Cl-].[Pb+2]    1.610660                  96.0    ITX   \n",
      "3       3  O=S(=O)([O-])[O-].[Cu+2]    0.278754                  24.0    ITX   \n",
      "4       4  O=S(=O)([O-])[O-].[Cu+2]   -0.221849                  96.0    ITX   \n",
      "\n",
      "  Endpoint  \n",
      "0     EC50  \n",
      "1     EC50  \n",
      "2     EC50  \n",
      "3     EC50  \n",
      "4     EC50  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# ========== 路径配置 ==========\n",
    "DATA_PATH = Path(\"/root/fusion_dataset/Invertebrates_EC50_unique.xlsx\")  # 换成你实际的数据集\n",
    "\n",
    "GRAPH_OUT_DIR = Path(\"/root/Invertebrates_EC50_multi_fusion/graph/graph_outputs\")\n",
    "GRAPH_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GRAPH_PT_PATH      = GRAPH_OUT_DIR / \"Invertebrates_EC50_graphs.pt\"   # 图对象列表\n",
    "GRAPH_ROWID_PATH   = GRAPH_OUT_DIR / \"row_id_graph.npy\"       # 每个图对应 df 的 row_id\n",
    "GRAPH_EMB_PATH     = GRAPH_OUT_DIR / \"reg_graph_embeddings.npy\"\n",
    "GRAPH_ROWID_EMB    = GRAPH_OUT_DIR / \"row_id_graph_for_emb.npy\"\n",
    "\n",
    "print(\"图数据将保存到:\", GRAPH_PT_PATH)\n",
    "print(\"row_id 将保存到:\", GRAPH_ROWID_PATH)\n",
    "print(\"图嵌入将保存到:\", GRAPH_EMB_PATH)\n",
    "\n",
    "# ========== 读 Excel ==========\n",
    "df = pd.read_excel(DATA_PATH, engine=\"openpyxl\")\n",
    "\n",
    "# 确保有 row_id\n",
    "if \"row_id\" not in df.columns:\n",
    "    df = df.reset_index().rename(columns={\"index\": \"row_id\"})\n",
    "df[\"row_id\"] = df[\"row_id\"].astype(int)\n",
    "\n",
    "# 标签：若没有 mgperL_log 就自己算一个（和文本端保持统一）\n",
    "if \"mgperL_log\" not in df.columns:\n",
    "    df[\"mgperL_log\"] = np.log10(df[\"mgperL\"].astype(float))\n",
    "\n",
    "required_cols = [\n",
    "    \"row_id\",\n",
    "    \"SMILES_Canonical_RDKit\",\n",
    "    \"mgperL_log\",\n",
    "    \"Duration_Value(hour)\",\n",
    "    \"Effect\",\n",
    "    \"Endpoint\",\n",
    "]\n",
    "for c in required_cols:\n",
    "    assert c in df.columns, f\"df 缺少列: {c}\"\n",
    "\n",
    "print(\"数据行数:\", len(df))\n",
    "print(df[required_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05801f7-aa28-4a9b-a9ae-153cbe678cf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3620 [00:00<?, ?it/s][00:26:27] SMILES Parse Error: syntax error while parsing: CCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 10:\n",
      "[00:26:27] CCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O\n",
      "[00:26:27] ~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'CCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCC' for input: 'CCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](|[Cl])(|[Cl])CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](|[Cl])(|[Cl])CCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](|[Cl])(|[Cl])CCCC' for input: '[Cl]|[Sn](|[Cl])(|[Cl])CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: CCCCCCCCCCCC[S]|[Sn](|[S]CCCCCCCCCCCC)(CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 16:\n",
      "[00:26:27] CCCCCCCCCCCC[S]|[Sn](|[S]CCCCCCCCCCCC)(CC\n",
      "[00:26:27] ~~~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCCCCCC[S]|[Sn](|[S]CCCCCCCCCCCC)(CCCC)CCCC' for input: 'CCCCCCCCCCCC[S]|[Sn](|[S]CCCCCCCCCCCC)(CCCC)CCCC'\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O|[Co](|O)|O\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:27] O|[Co](|O)|O\n",
      "[00:26:27] ~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O|[Co](|O)|O' for input: 'O|[Co](|O)|O'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O|[Co](|O)|O\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:27] O|[Co](|O)|O\n",
      "[00:26:27] ~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O|[Co](|O)|O' for input: 'O|[Co](|O)|O'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O|[Co](|O)|O\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:27] O|[Co](|O)|O\n",
      "[00:26:27] ~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O|[Co](|O)|O' for input: 'O|[Co](|O)|O'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O|[Co](|O)|O\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:27] O|[Co](|O)|O\n",
      "[00:26:27] ~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O|[Co](|O)|O' for input: 'O|[Co](|O)|O'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O|[Co](|O)|O\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:27] O|[Co](|O)|O\n",
      "[00:26:27] ~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O|[Co](|O)|O' for input: 'O|[Co](|O)|O'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [K+].[K+].[K+].[Fe-3](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 23:\n",
      "[00:26:27] +].[K+].[K+].[Fe-3](|[C]#N)(|[C]#N)(|[C]#\n",
      "[00:26:27] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[K+].[K+].[K+].[Fe-3](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N' for input: '[K+].[K+].[K+].[Fe-3](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](CCCC)(CCCC)CCCC' for input: '[Cl]|[Sn](CCCC)(CCCC)CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](CCCC)(CCCC)CCCC' for input: '[Cl]|[Sn](CCCC)(CCCC)CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](CCCC)(CCCC)CCCC' for input: '[Cl]|[Sn](CCCC)(CCCC)CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](CCCC)(CCCC)CCCC' for input: '[Cl]|[Sn](CCCC)(CCCC)CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](CCCC)(CCCC)CCCC' for input: '[Cl]|[Sn](CCCC)(CCCC)CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 19:\n",
      "[00:26:27] [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]' for input: '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 19:\n",
      "[00:26:27] [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]' for input: '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 19:\n",
      "[00:26:27] [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]' for input: '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 19:\n",
      "[00:26:27] [NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]' for input: '[NH4+].[NH4+].[Cl]|[Zn--](|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 13:\n",
      "[00:26:27] CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC\n",
      "[00:26:27] ~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC' for input: 'CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 13:\n",
      "[00:26:27] CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC\n",
      "[00:26:27] ~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC' for input: 'CCCCCCCC[Sn]|1(|[O]C(=O)C[S]|1)CCCCCCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCCCCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:27] CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]C\n",
      "[00:26:27] ~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCCCCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCCCCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:27] CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]C\n",
      "[00:26:27] ~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)CCCCCCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]' for input: '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]' for input: '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[H+].[H+]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[H+].[H+]' for input: '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[H+].[H+]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[H+].[H+]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[H+].[H+]' for input: '[Cl]|[Pt--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[H+].[H+]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O(|[Ag])|[Ag]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:27] O(|[Ag])|[Ag]\n",
      "[00:26:27] ~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O(|[Ag])|[Ag]' for input: 'O(|[Ag])|[Ag]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O(|[Ag])|[Ag]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:27] O(|[Ag])|[Ag]\n",
      "[00:26:27] ~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O(|[Ag])|[Ag]' for input: 'O(|[Ag])|[Ag]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O(|[Ag])|[Ag]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:27] O(|[Ag])|[Ag]\n",
      "[00:26:27] ~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O(|[Ag])|[Ag]' for input: 'O(|[Ag])|[Ag]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: O(|[Ag])|[Ag]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:27] O(|[Ag])|[Ag]\n",
      "[00:26:27] ~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES 'O(|[Ag])|[Ag]' for input: 'O(|[Ag])|[Ag]'\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](|[Cl])(CCCCCCCC)CCCCCCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](|[Cl])(CCCCCCCC)CCCCCCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](|[Cl])(CCCCCCCC)CCCCCCCC' for input: '[Cl]|[Sn](|[Cl])(CCCCCCCC)CCCCCCCC'\n",
      "  7%|▋         | 241/3620 [00:00<00:01, 2393.47it/s][00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](|[Cl])(CCCC)CCCC\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](|[Cl])(CCCC)CCCC\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](|[Cl])(CCCC)CCCC' for input: '[Cl]|[Sn](|[Cl])(CCCC)CCCC'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](|[Cl])(C)C\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sn](|[Cl])(C)C\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](|[Cl])(C)C' for input: '[Cl]|[Sn](|[Cl])(C)C'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      " 20%|█▉        | 719/3620 [00:00<00:01, 2212.13it/s][00:26:27] SMILES Parse Error: syntax error while parsing: [Na+].[Na+].[Cu]|1|OC(=O)CN(CCN(CC(O|1)=O)CC([O-])=O)CC([O-])=O\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 17:\n",
      "[00:26:27] [Na+].[Na+].[Cu]|1|OC(=O)CN(CCN(CC(O|1)=O\n",
      "[00:26:27] ~~~~~~~~~~~~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Na+].[Na+].[Cu]|1|OC(=O)CN(CCN(CC(O|1)=O)CC([O-])=O)CC([O-])=O' for input: '[Na+].[Na+].[Cu]|1|OC(=O)CN(CCN(CC(O|1)=O)CC([O-])=O)CC([O-])=O'\n",
      " 26%|██▌       | 942/3620 [00:00<00:01, 2099.90it/s][00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:27] SMILES Parse Error: syntax error while parsing: [Ni]|1|2(|[O]C(=CC(=[OH]|1)C)C)|[O]C(=CC(=[OH]|2)C)C\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:27] [Ni]|1|2(|[O]C(=CC(=[OH]|1)C)C)|[O]C(=CC(\n",
      "[00:26:27] ~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Ni]|1|2(|[O]C(=CC(=[OH]|1)C)C)|[O]C(=CC(=[OH]|2)C)C' for input: '[Ni]|1|2(|[O]C(=CC(=[OH]|1)C)C)|[O]C(=CC(=[OH]|2)C)C'\n",
      " 32%|███▏      | 1154/3620 [00:00<00:01, 1928.71it/s][00:26:27] SMILES Parse Error: syntax error while parsing: [Zn](|OC(=O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO)|OC(=O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO\n",
      "[00:26:27] SMILES Parse Error: check for mistakes around position 6:\n",
      "[00:26:27] [Zn](|OC(=O)[C@H](O)[C@@H](O)[C@H](O)[C@H\n",
      "[00:26:27] ~~~~~^\n",
      "[00:26:27] SMILES Parse Error: Failed parsing SMILES '[Zn](|OC(=O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO)|OC(=O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO' for input: '[Zn](|OC(=O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO)|OC(=O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO'\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: [Zn++](|[C-]#N)|[C-]#N\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 8:\n",
      "[00:26:28] [Zn++](|[C-]#N)|[C-]#N\n",
      "[00:26:28] ~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES '[Zn++](|[C-]#N)|[C-]#N' for input: '[Zn++](|[C-]#N)|[C-]#N'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: [Zn++](|[C-]#N)|[C-]#N\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 8:\n",
      "[00:26:28] [Zn++](|[C-]#N)|[C-]#N\n",
      "[00:26:28] ~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES '[Zn++](|[C-]#N)|[C-]#N' for input: '[Zn++](|[C-]#N)|[C-]#N'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: O(|[Sn](CCCC)(CCCC)CCCC)|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:28] O(|[Sn](CCCC)(CCCC)CCCC)|[Sn](CCCC)(CCCC)\n",
      "[00:26:28] ~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'O(|[Sn](CCCC)(CCCC)CCCC)|[Sn](CCCC)(CCCC)CCCC' for input: 'O(|[Sn](CCCC)(CCCC)CCCC)|[Sn](CCCC)(CCCC)CCCC'\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: [Na+].[Na+].[Na+].[Cr+3]|1|2|3|4(|[O-]c5ccc6ccccc6c5N=N|1c7c([O-]|2)cc(c8cc(ccc78)[N+]([O-])=O)[S]([O-])(=O)=O)|[O-]c9ccc%10ccccc%10c9N=N|3c%11c([O-]|4)cc(c%12cc(ccc%11%12)[N+]([O-])=O)[S]([O-])(=O)=O\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 25:\n",
      "[00:26:28] ].[Na+].[Na+].[Cr+3]|1|2|3|4(|[O-]c5ccc6c\n",
      "[00:26:28] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES '[Na+].[Na+].[Na+].[Cr+3]|1|2|3|4(|[O-]c5ccc6ccccc6c5N=N|1c7c([O-]|2)cc(c8cc(ccc78)[N+]([O-])=O)[S]([O-])(=O)=O)|[O-]c9ccc%10ccccc%10c9N=N|3c%11c([O-]|4)cc(c%12cc(ccc%11%12)[N+]([O-])=O)[S]([O-])(=O)=O' for input: '[Na+].[Na+].[Na+].[Cr+3]|1|2|3|4(|[O-]c5ccc6ccccc6c5N=N|1c7c([O-]|2)cc(c8cc(ccc78)[N+]([O-])=O)[S]([O-])(=O)=O)|[O-]c9ccc%10ccccc%10c9N=N|3c%11c([O-]|4)cc(c%12cc(ccc%11%12)[N+]([O-])=O)[S]([O-])(=O)=O'\n",
      " 37%|███▋      | 1349/3620 [00:00<00:01, 1811.13it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      " 42%|████▏     | 1532/3620 [00:00<00:01, 1761.96it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      " 47%|████▋     | 1716/3620 [00:00<00:01, 1783.14it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      " 52%|█████▏    | 1896/3620 [00:01<00:01, 1714.00it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: O|[Zn]|OC(=O)C(C)=C\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:28] O|[Zn]|OC(=O)C(C)=C\n",
      "[00:26:28] ~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'O|[Zn]|OC(=O)C(C)=C' for input: 'O|[Zn]|OC(=O)C(C)=C'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:28] CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(\n",
      "[00:26:28] ~~~~~~~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:28] CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(\n",
      "[00:26:28] ~~~~~~~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:28] CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(\n",
      "[00:26:28] ~~~~~~~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:28] CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(\n",
      "[00:26:28] ~~~~~~~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:28] CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(\n",
      "[00:26:28] ~~~~~~~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC'\n",
      " 57%|█████▋    | 2077/3620 [00:01<00:00, 1740.30it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: O|[Hg]c1c([O-])c(Br)cc2c1Oc3cc([O-])c(Br)cc3C24OC(=O)c5ccccc45.[Na+].[Na+]\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:28] O|[Hg]c1c([O-])c(Br)cc2c1Oc3cc([O-])c(Br)\n",
      "[00:26:28] ~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'O|[Hg]c1c([O-])c(Br)cc2c1Oc3cc([O-])c(Br)cc3C24OC(=O)c5ccccc45.[Na+].[Na+]' for input: 'O|[Hg]c1c([O-])c(Br)cc2c1Oc3cc([O-])c(Br)cc3C24OC(=O)c5ccccc45.[Na+].[Na+]'\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      " 62%|██████▏   | 2252/3620 [00:01<00:00, 1703.50it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: O|[In](|O)|O\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:28] O|[In](|O)|O\n",
      "[00:26:28] ~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'O|[In](|O)|O' for input: 'O|[In](|O)|O'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: O|[In](|O)|O\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:28] O|[In](|O)|O\n",
      "[00:26:28] ~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'O|[In](|O)|O' for input: 'O|[In](|O)|O'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: O|[In](|O)|O\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:28] O|[In](|O)|O\n",
      "[00:26:28] ~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'O|[In](|O)|O' for input: 'O|[In](|O)|O'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: [Na+].[Na+].[Na+].[Na+].[Cu]|1|Oc2cc(ccc2N\\N=C\\3C(=O|1)c4c(N)cc(cc4C=C3[S]([O-])(=O)=O)[S]([O-])(=O)=O)c5ccc6N\\N=C\\7C(=O|[Cu]|Oc6c5)c8c(N)cc(cc8C=C7[S]([O-])(=O)=O)[S]([O-])(=O)=O\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 29:\n",
      "[00:26:28] a+].[Na+].[Na+].[Cu]|1|Oc2cc(ccc2N\\N=C\\3C\n",
      "[00:26:28] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES '[Na+].[Na+].[Na+].[Na+].[Cu]|1|Oc2cc(ccc2N\\N=C\\3C(=O|1)c4c(N)cc(cc4C=C3[S]([O-])(=O)=O)[S]([O-])(=O)=O)c5ccc6N\\N=C\\7C(=O|[Cu]|Oc6c5)c8c(N)cc(cc8C=C7[S]([O-])(=O)=O)[S]([O-])(=O)=O' for input: '[Na+].[Na+].[Na+].[Na+].[Cu]|1|Oc2cc(ccc2N\\N=C\\3C(=O|1)c4c(N)cc(cc4C=C3[S]([O-])(=O)=O)[S]([O-])(=O)=O)c5ccc6N\\N=C\\7C(=O|[Cu]|Oc6c5)c8c(N)cc(cc8C=C7[S]([O-])(=O)=O)[S]([O-])(=O)=O'\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      " 67%|██████▋   | 2423/3620 [00:01<00:00, 1656.63it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: [OH-]|[Pt](|[OH-])(|[OH-])(|[OH-])(|[OH-])|[OH-].[H+].[H+]\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 6:\n",
      "[00:26:28] [OH-]|[Pt](|[OH-])(|[OH-])(|[OH-])(|[OH-]\n",
      "[00:26:28] ~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES '[OH-]|[Pt](|[OH-])(|[OH-])(|[OH-])(|[OH-])|[OH-].[H+].[H+]' for input: '[OH-]|[Pt](|[OH-])(|[OH-])(|[OH-])(|[OH-])|[OH-].[H+].[H+]'\n",
      " 72%|███████▏  | 2590/3620 [00:01<00:00, 1596.55it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: [Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC)|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC.[H+].[H+]\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 8:\n",
      "[00:26:28] [Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC\n",
      "[00:26:28] ~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES '[Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC)|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC.[H+].[H+]' for input: '[Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC)|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC.[H+].[H+]'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: [Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC)|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC.[H+].[H+]\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 8:\n",
      "[00:26:28] [Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC\n",
      "[00:26:28] ~~~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES '[Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC)|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC.[H+].[H+]' for input: '[Ti+4](|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]CC(CC)(COCC=C)COCC=C)(|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC)|[O-]P(OCCCCCCCCCCCCC)OCCCCCCCCCCCCC.[H+].[H+]'\n",
      "[00:26:28] SMILES Parse Error: syntax error while parsing: N.N.O|[Ti](|O)(|OC(C)C(O)=O)|OC(C)C(O)=O\n",
      "[00:26:28] SMILES Parse Error: check for mistakes around position 6:\n",
      "[00:26:28] N.N.O|[Ti](|O)(|OC(C)C(O)=O)|OC(C)C(O)=O\n",
      "[00:26:28] ~~~~~^\n",
      "[00:26:28] SMILES Parse Error: Failed parsing SMILES 'N.N.O|[Ti](|O)(|OC(C)C(O)=O)|OC(C)C(O)=O' for input: 'N.N.O|[Ti](|O)(|OC(C)C(O)=O)|OC(C)C(O)=O'\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      " 76%|███████▌  | 2751/3620 [00:01<00:00, 1529.91it/s][00:26:28] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      " 81%|████████  | 2920/3620 [00:01<00:00, 1568.10it/s][00:26:29] SMILES Parse Error: syntax error while parsing: O(|[Ag])|[Ag]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:29] O(|[Ag])|[Ag]\n",
      "[00:26:29] ~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O(|[Ag])|[Ag]' for input: 'O(|[Ag])|[Ag]'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: O(|[Ag])|[Ag]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:29] O(|[Ag])|[Ag]\n",
      "[00:26:29] ~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O(|[Ag])|[Ag]' for input: 'O(|[Ag])|[Ag]'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: O(|[Ag])|[Ag]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:29] O(|[Ag])|[Ag]\n",
      "[00:26:29] ~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O(|[Ag])|[Ag]' for input: 'O(|[Ag])|[Ag]'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc2)CC(C)(C)c3ccccc3)|[Sn](CC(C)(C)c4ccccc4)(CC(C)(C)c5ccccc5)CC(C)(C)c6ccccc6\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:29] O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc\n",
      "[00:26:29] ~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc2)CC(C)(C)c3ccccc3)|[Sn](CC(C)(C)c4ccccc4)(CC(C)(C)c5ccccc5)CC(C)(C)c6ccccc6' for input: 'O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc2)CC(C)(C)c3ccccc3)|[Sn](CC(C)(C)c4ccccc4)(CC(C)(C)c5ccccc5)CC(C)(C)c6ccccc6'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: O|[Co](|O)|O\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:29] O|[Co](|O)|O\n",
      "[00:26:29] ~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O|[Co](|O)|O' for input: 'O|[Co](|O)|O'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:29] [Cl]|[Sn](CCCC)(CCCC)CCCC\n",
      "[00:26:29] ~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sn](CCCC)(CCCC)CCCC' for input: '[Cl]|[Sn](CCCC)(CCCC)CCCC'\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: [Cl]|[Pd--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:29] [Cl]|[Pd--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[\n",
      "[00:26:29] ~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Pd--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]' for input: '[Cl]|[Pd--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl].[K+].[K+]'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: [NH4+].[NH4+].[Cl]|[Pd--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 19:\n",
      "[00:26:29] [NH4+].[NH4+].[Cl]|[Pd--](|[Cl])(|[Cl])(|\n",
      "[00:26:29] ~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[NH4+].[NH4+].[Cl]|[Pd--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[NH4+].[NH4+].[Cl]|[Pd--](|[Cl])(|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: O|[Pd]|O\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:29] O|[Pd]|O\n",
      "[00:26:29] ~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O|[Pd]|O' for input: 'O|[Pd]|O'\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc2)CC(C)(C)c3ccccc3)|[Sn](CC(C)(C)c4ccccc4)(CC(C)(C)c5ccccc5)CC(C)(C)c6ccccc6\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 3:\n",
      "[00:26:29] O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc\n",
      "[00:26:29] ~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc2)CC(C)(C)c3ccccc3)|[Sn](CC(C)(C)c4ccccc4)(CC(C)(C)c5ccccc5)CC(C)(C)c6ccccc6' for input: 'O(|[Sn](CC(C)(C)c1ccccc1)(CC(C)(C)c2ccccc2)CC(C)(C)c3ccccc3)|[Sn](CC(C)(C)c4ccccc4)(CC(C)(C)c5ccccc5)CC(C)(C)c6ccccc6'\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: [NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[Cl].[Cl]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 7:\n",
      "[00:26:29] [NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[C\n",
      "[00:26:29] ~~~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[Cl].[Cl]' for input: '[NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[Cl].[Cl]'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: [NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[Cl].[Cl]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 7:\n",
      "[00:26:29] [NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[C\n",
      "[00:26:29] ~~~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[Cl].[Cl]' for input: '[NH2-]|[Pd++](|[NH2-])(|[NH2-])|[NH2-].[Cl].[Cl]'\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      " 86%|████████▌ | 3122/3620 [00:01<00:00, 1692.39it/s][00:26:29] SMILES Parse Error: syntax error while parsing: O|[Co](|O)|O\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 2:\n",
      "[00:26:29] O|[Co](|O)|O\n",
      "[00:26:29] ~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'O|[Co](|O)|O' for input: 'O|[Co](|O)|O'\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] Explicit valence for atom # 1 O, 4, is greater than permitted\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 5:\n",
      "[00:26:29] [Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]\n",
      "[00:26:29] ~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]' for input: '[Cl]|[Sb](|[Cl])(|[Cl])(|[Cl])|[Cl]'\n",
      " 92%|█████████▏| 3328/3620 [00:01<00:00, 1793.30it/s][00:26:29] Explicit valence for atom # 17 O, 2, is greater than permitted\n",
      "[00:26:29] Explicit valence for atom # 0 O, 2, is greater than permitted\n",
      "[00:26:29] WARNING: not removing hydrogen atom without neighbors\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:29] CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(\n",
      "[00:26:29] ~~~~~~~~~~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC' for input: 'CCCCCCCC[Sn](|[O]C(=O)C(C)(C)CCC(C)(C)C)(|[O]C(=O)C(C)(C)CCC(C)(C)C)CCCCCCCC'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)|[S]CC(=O)OCC(CC)CCCC\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 14:\n",
      "[00:26:29] CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]C\n",
      "[00:26:29] ~~~~~~~~~~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES 'CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)|[S]CC(=O)OCC(CC)CCCC' for input: 'CCCCCCCC[Sn](|[S]CC(=O)OCC(CC)CCCC)(|[S]CC(=O)OCC(CC)CCCC)|[S]CC(=O)OCC(CC)CCCC'\n",
      " 97%|█████████▋| 3510/3620 [00:01<00:00, 1800.51it/s][00:26:29] SMILES Parse Error: syntax error while parsing: [Na+].[Na+].[Na+].[Na+].[Fe-4](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 32:\n",
      "[00:26:29] .[Na+].[Na+].[Fe-4](|[C]#N)(|[C]#N)(|[C]#\n",
      "[00:26:29] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[Na+].[Na+].[Na+].[Na+].[Fe-4](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N' for input: '[Na+].[Na+].[Na+].[Na+].[Fe-4](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N'\n",
      "[00:26:29] SMILES Parse Error: syntax error while parsing: [K+].[K+].[K+].[K+].[Fe](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N\n",
      "[00:26:29] SMILES Parse Error: check for mistakes around position 26:\n",
      "[00:26:29] [K+].[K+].[K+].[Fe](|[C]#N)(|[C]#N)(|[C]#\n",
      "[00:26:29] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[00:26:29] SMILES Parse Error: Failed parsing SMILES '[K+].[K+].[K+].[K+].[Fe](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N' for input: '[K+].[K+].[K+].[K+].[Fe](|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)(|[C]#N)|[C]#N'\n",
      "100%|██████████| 3620/3620 [00:02<00:00, 1799.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功构建图样本数: 3213\n",
      "✅ graph_list 已保存: /root/Invertebrates_EC50_multi_fusion/graph/graph_outputs/Invertebrates_EC50_graphs.pt\n",
      "✅ row_id_graph 已保存: /root/Invertebrates_EC50_multi_fusion/graph/graph_outputs/row_id_graph.npy\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdchem\n",
    "\n",
    "# ========= 一些辅助配置 =========\n",
    "ATOM_LIST = [\"C\",\"N\",\"O\",\"F\",\"Cl\",\"Br\",\"I\",\"S\",\"P\",\"B\",\"Si\",\"other\"]\n",
    "HYB_LIST  = [\n",
    "    rdchem.HybridizationType.SP,\n",
    "    rdchem.HybridizationType.SP2,\n",
    "    rdchem.HybridizationType.SP3,\n",
    "    rdchem.HybridizationType.SP3D,\n",
    "    rdchem.HybridizationType.SP3D2,\n",
    "    \"other\"\n",
    "]\n",
    "\n",
    "def one_hot(x, allowed):\n",
    "    return [int(x == a) for a in allowed]\n",
    "\n",
    "def atom_to_feature(atom: Chem.Atom):\n",
    "    \"\"\"\n",
    "    节点特征：\n",
    "    - 元素 one-hot\n",
    "    - 原子度数 degree (0-5, 6+)\n",
    "    - 形式电荷 formal charge (-2~2)\n",
    "    - 杂化态 hybridization\n",
    "    - 总氢数 (0-4, 5+)\n",
    "    - 是否在环中\n",
    "    - 是否芳香\n",
    "    - 手性标签（可以视为可选）\n",
    "    \"\"\"\n",
    "    symbol = atom.GetSymbol()\n",
    "    if symbol not in ATOM_LIST:\n",
    "        symbol = \"other\"\n",
    "\n",
    "    hyb = atom.GetHybridization()\n",
    "    if hyb not in HYB_LIST:\n",
    "        hyb = \"other\"\n",
    "\n",
    "    # 元素 one-hot\n",
    "    feat_symbol = one_hot(symbol, ATOM_LIST)\n",
    "\n",
    "    # 度数（0-5, >=6）\n",
    "    deg = atom.GetDegree()\n",
    "    deg_list = [0,1,2,3,4,5,\"6+\"]\n",
    "    deg_clamp = deg if deg <= 5 else \"6+\"\n",
    "    feat_degree = one_hot(deg_clamp, deg_list)\n",
    "\n",
    "    # 形式电荷（-2, -1, 0, 1, 2）\n",
    "    fc = atom.GetFormalCharge()\n",
    "    fc_list = [-2,-1,0,1,2]\n",
    "    fc_clamp = fc if fc in fc_list else 0\n",
    "    feat_charge = one_hot(fc_clamp, fc_list)\n",
    "\n",
    "    # 杂化态\n",
    "    feat_hyb = one_hot(hyb, HYB_LIST)\n",
    "\n",
    "    # 氢原子个数（0-4, >=5）\n",
    "    num_h = atom.GetTotalNumHs()\n",
    "    h_list = [0,1,2,3,4,\"5+\"]\n",
    "    h_clamp = num_h if num_h <= 4 else \"5+\"\n",
    "    feat_num_h = one_hot(h_clamp, h_list)\n",
    "\n",
    "    # 在环 / 芳香性\n",
    "    feat_ring      = [int(atom.IsInRing())]\n",
    "    feat_aromatic  = [int(atom.GetIsAromatic())]\n",
    "\n",
    "    # 手性信息（可选）\n",
    "    chiral_tag = atom.GetChiralTag()\n",
    "    chiral_list = [\n",
    "        rdchem.ChiralType.CHI_UNSPECIFIED,\n",
    "        rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
    "        rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
    "        \"other\"\n",
    "    ]\n",
    "    if chiral_tag not in chiral_list:\n",
    "        chiral_tag = \"other\"\n",
    "    feat_chiral = one_hot(chiral_tag, chiral_list)\n",
    "\n",
    "    feat = (\n",
    "        feat_symbol +\n",
    "        feat_degree +\n",
    "        feat_charge +\n",
    "        feat_hyb +\n",
    "        feat_num_h +\n",
    "        feat_ring +\n",
    "        feat_aromatic +\n",
    "        feat_chiral\n",
    "    )\n",
    "    return feat\n",
    "\n",
    "\n",
    "def bond_to_feature(bond: Chem.Bond):\n",
    "    \"\"\"\n",
    "    边特征：\n",
    "    - bond type one-hot (single/double/triple/other)\n",
    "    - 是否共轭\n",
    "    - 是否在环中\n",
    "    （stereo 想加也可以再扩一组 one-hot）\n",
    "    \"\"\"\n",
    "    bt = bond.GetBondType()\n",
    "    if bt == rdchem.BondType.SINGLE:\n",
    "        bt_vec = [1,0,0,0]\n",
    "    elif bt == rdchem.BondType.DOUBLE:\n",
    "        bt_vec = [0,1,0,0]\n",
    "    elif bt == rdchem.BondType.TRIPLE:\n",
    "        bt_vec = [0,0,1,0]\n",
    "    else:\n",
    "        bt_vec = [0,0,0,1]  # aromatic or others\n",
    "\n",
    "    conj    = [int(bond.GetIsConjugated())]\n",
    "    in_ring = [int(bond.IsInRing())]\n",
    "\n",
    "    return bt_vec + conj + in_ring   # 总维度 = 4 + 1 + 1 = 6\n",
    "\n",
    "\n",
    "def mol_to_graph(smiles, y, row_id):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    # ------- 节点特征 -------\n",
    "    atom_feats = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_feats.append(atom_to_feature(atom))\n",
    "    x = torch.tensor(atom_feats, dtype=torch.float32)\n",
    "\n",
    "    # ------- 边特征 -------\n",
    "    edge_index_list = []\n",
    "    edge_attr_list  = []\n",
    "\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        bfeat = bond_to_feature(bond)\n",
    "\n",
    "        # 无向图：i->j, j->i\n",
    "        edge_index_list.append([i, j])\n",
    "        edge_index_list.append([j, i])\n",
    "        edge_attr_list.append(bfeat)\n",
    "        edge_attr_list.append(bfeat)\n",
    "\n",
    "    if len(edge_index_list) == 0:\n",
    "        # 没键的奇怪分子，直接跳过\n",
    "        return None\n",
    "\n",
    "    edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()  # (2, E)\n",
    "    edge_attr  = torch.tensor(edge_attr_list, dtype=torch.float32)                 # (E, edge_dim)\n",
    "\n",
    "    y_tensor      = torch.tensor([y], dtype=torch.float32)\n",
    "    row_id_tensor = torch.tensor([row_id], dtype=torch.long)\n",
    "\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        y=y_tensor,\n",
    "        row_id=row_id_tensor,\n",
    "    )\n",
    "    return data\n",
    "\n",
    "# ===== 批量构图（这段和原来的 Cell 1 一样，可以保留）=====\n",
    "graph_list = []\n",
    "valid_row_ids = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    smiles = row[\"SMILES_Canonical_RDKit\"]\n",
    "    y      = float(row[\"mgperL_log\"])\n",
    "    rid    = int(row[\"row_id\"])\n",
    "\n",
    "    g = mol_to_graph(smiles, y, rid)\n",
    "    if g is None:\n",
    "        continue\n",
    "\n",
    "    graph_list.append(g)\n",
    "    valid_row_ids.append(rid)\n",
    "\n",
    "print(f\"成功构建图样本数: {len(graph_list)}\")\n",
    "\n",
    "row_id_graph = np.array(valid_row_ids, dtype=np.int64)\n",
    "\n",
    "torch.save(graph_list, GRAPH_PT_PATH)\n",
    "np.save(GRAPH_ROWID_PATH, row_id_graph)\n",
    "\n",
    "print(\"✅ graph_list 已保存:\", GRAPH_PT_PATH)\n",
    "print(\"✅ row_id_graph 已保存:\", GRAPH_ROWID_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a856b2-b54d-43e8-b935-5fe6c972753a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d212105e-fd3d-4e92-81fe-b7557b4db921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1760/4169944597.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_list = torch.load(GRAPH_PT_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图样本数: 3213\n",
      "smiles_all_graph 长度: 3213\n",
      "GNN train 样本数: 2573\n",
      "GNN val   样本数: 640\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# 重新读一遍 graph_list 和 row_id_graph（保证从磁盘加载）\n",
    "graph_list = torch.load(GRAPH_PT_PATH)\n",
    "row_id_graph = np.load(GRAPH_ROWID_PATH)\n",
    "\n",
    "print(\"图样本数:\", len(graph_list))\n",
    "\n",
    "# 按 row_id 回到 df，拿到 SMILES 作为 group\n",
    "df_indexed = df.set_index(\"row_id\")\n",
    "smiles_all_graph = df_indexed.loc[row_id_graph, \"SMILES_Canonical_RDKit\"].values\n",
    "\n",
    "print(\"smiles_all_graph 长度:\", len(smiles_all_graph))\n",
    "\n",
    "groups = smiles_all_graph  # 每个图的 group 标签就是对应 SMILES\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=42)\n",
    "train_idx_gnn, val_idx_gnn = next(gss.split(np.zeros(len(row_id_graph)), groups=groups))\n",
    "\n",
    "train_idx_gnn = np.array(train_idx_gnn, dtype=np.int64)\n",
    "val_idx_gnn   = np.array(val_idx_gnn, dtype=np.int64)\n",
    "\n",
    "print(\"GNN train 样本数:\", len(train_idx_gnn))\n",
    "print(\"GNN val   样本数:\", len(val_idx_gnn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a369d-c9e7-4b50-9af6-976c903b9df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e059a2-c8e8-4654-a399-c327ffdfaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data_list, indices):\n",
    "        self.data_list = data_list\n",
    "        self.indices = np.array(indices, dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[self.indices[idx]]\n",
    "\n",
    "class GATv2Regressor(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=256, num_layers=2, heads=4, edge_dim=None, dropout=0.05):\n",
    "        super().__init__()\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "\n",
    "        assert heads == 1 or hidden_channels % heads == 0, \"hidden_channels 必须能被 heads 整除\"\n",
    "\n",
    "        out_channels = hidden_channels // heads if heads > 1 else hidden_channels\n",
    "\n",
    "        # 第一层\n",
    "        self.convs.append(\n",
    "            GATv2Conv(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                heads=heads,\n",
    "                concat=(heads > 1),\n",
    "                dropout=dropout,\n",
    "                edge_dim=edge_dim,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 后续层\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(\n",
    "                GATv2Conv(\n",
    "                    hidden_channels,\n",
    "                    out_channels,\n",
    "                    heads=heads,\n",
    "                    concat=(heads > 1),\n",
    "                    dropout=dropout,\n",
    "                    edge_dim=edge_dim,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # 图级 pooling 之后接一个回归头\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, 1),\n",
    "        )\n",
    "\n",
    "    def encode_graph(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        edge_attr = getattr(data, \"edge_attr\", None)\n",
    "        batch = data.batch\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = F.elu(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # 图级 embedding\n",
    "        graph_emb = global_mean_pool(x, batch)  # (B, hidden_channels)\n",
    "        return graph_emb\n",
    "\n",
    "    def forward(self, data):\n",
    "        graph_emb = self.encode_graph(data)\n",
    "        out = self.reg_head(graph_emb).squeeze(-1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2fea21-4aa2-4146-8936-a77e436f03cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "[GNN] Epoch 1/100 | TrainLoss=0.9977 | ValLoss=0.9309 | Val_R2=-0.1131 | Val_MAE=0.9309\n",
      "[GNN] Epoch 2/100 | TrainLoss=0.9219 | ValLoss=0.8946 | Val_R2=-0.0115 | Val_MAE=0.8946\n",
      "[GNN] Epoch 3/100 | TrainLoss=0.9122 | ValLoss=0.8907 | Val_R2=-0.0192 | Val_MAE=0.8907\n",
      "[GNN] Epoch 4/100 | TrainLoss=0.9083 | ValLoss=0.8935 | Val_R2=-0.0611 | Val_MAE=0.8935\n",
      "[GNN] Epoch 5/100 | TrainLoss=0.9004 | ValLoss=0.8673 | Val_R2=0.0428 | Val_MAE=0.8673\n",
      "[GNN] Epoch 6/100 | TrainLoss=0.8866 | ValLoss=0.8377 | Val_R2=0.0815 | Val_MAE=0.8377\n",
      "[GNN] Epoch 7/100 | TrainLoss=0.8721 | ValLoss=0.8330 | Val_R2=-0.0085 | Val_MAE=0.8330\n",
      "[GNN] Epoch 8/100 | TrainLoss=0.8317 | ValLoss=0.8093 | Val_R2=0.1251 | Val_MAE=0.8093\n",
      "[GNN] Epoch 9/100 | TrainLoss=0.8143 | ValLoss=0.7838 | Val_R2=0.0689 | Val_MAE=0.7838\n",
      "[GNN] Epoch 10/100 | TrainLoss=0.8077 | ValLoss=0.8028 | Val_R2=-0.0028 | Val_MAE=0.8028\n",
      "[GNN] Epoch 11/100 | TrainLoss=0.7995 | ValLoss=0.7967 | Val_R2=0.0412 | Val_MAE=0.7967\n",
      "[GNN] Epoch 12/100 | TrainLoss=0.7928 | ValLoss=0.7693 | Val_R2=0.1724 | Val_MAE=0.7693\n",
      "[GNN] Epoch 13/100 | TrainLoss=0.7835 | ValLoss=0.7952 | Val_R2=0.1597 | Val_MAE=0.7952\n",
      "[GNN] Epoch 14/100 | TrainLoss=0.7612 | ValLoss=0.8179 | Val_R2=-0.0549 | Val_MAE=0.8179\n",
      "[GNN] Epoch 15/100 | TrainLoss=0.7792 | ValLoss=0.8302 | Val_R2=0.1078 | Val_MAE=0.8302\n",
      "[GNN] Epoch 16/100 | TrainLoss=0.7482 | ValLoss=0.8174 | Val_R2=0.1246 | Val_MAE=0.8174\n",
      "[GNN] Epoch 17/100 | TrainLoss=0.7634 | ValLoss=0.7859 | Val_R2=0.0294 | Val_MAE=0.7859\n",
      "[GNN] Epoch 18/100 | TrainLoss=0.7509 | ValLoss=0.7479 | Val_R2=0.2678 | Val_MAE=0.7479\n",
      "[GNN] Epoch 19/100 | TrainLoss=0.7355 | ValLoss=0.7519 | Val_R2=0.1779 | Val_MAE=0.7519\n",
      "[GNN] Epoch 20/100 | TrainLoss=0.7371 | ValLoss=0.9049 | Val_R2=-0.1438 | Val_MAE=0.9049\n",
      "[GNN] Epoch 21/100 | TrainLoss=0.7427 | ValLoss=0.7674 | Val_R2=0.0971 | Val_MAE=0.7674\n",
      "[GNN] Epoch 22/100 | TrainLoss=0.7344 | ValLoss=0.8001 | Val_R2=0.1335 | Val_MAE=0.8001\n",
      "[GNN] Epoch 23/100 | TrainLoss=0.7328 | ValLoss=0.7427 | Val_R2=0.2331 | Val_MAE=0.7427\n",
      "[GNN] Epoch 24/100 | TrainLoss=0.7313 | ValLoss=0.7453 | Val_R2=0.2665 | Val_MAE=0.7453\n",
      "[GNN] Epoch 25/100 | TrainLoss=0.7446 | ValLoss=0.7365 | Val_R2=0.2212 | Val_MAE=0.7365\n",
      "[GNN] Epoch 26/100 | TrainLoss=0.7456 | ValLoss=0.7218 | Val_R2=0.2168 | Val_MAE=0.7218\n",
      "[GNN] Epoch 27/100 | TrainLoss=0.7325 | ValLoss=0.9067 | Val_R2=0.0319 | Val_MAE=0.9067\n",
      "[GNN] Epoch 28/100 | TrainLoss=0.7215 | ValLoss=0.7646 | Val_R2=-0.0069 | Val_MAE=0.7646\n",
      "[GNN] Epoch 29/100 | TrainLoss=0.6880 | ValLoss=0.7277 | Val_R2=0.2772 | Val_MAE=0.7277\n",
      "[GNN] Epoch 30/100 | TrainLoss=0.6980 | ValLoss=0.7192 | Val_R2=0.2283 | Val_MAE=0.7192\n",
      "[GNN] Epoch 31/100 | TrainLoss=0.6976 | ValLoss=0.7011 | Val_R2=0.2373 | Val_MAE=0.7011\n",
      "[GNN] Epoch 32/100 | TrainLoss=0.6715 | ValLoss=0.6903 | Val_R2=0.2656 | Val_MAE=0.6903\n",
      "[GNN] Epoch 33/100 | TrainLoss=0.6740 | ValLoss=0.8861 | Val_R2=0.0789 | Val_MAE=0.8861\n",
      "[GNN] Epoch 34/100 | TrainLoss=0.7158 | ValLoss=0.7440 | Val_R2=0.1747 | Val_MAE=0.7440\n",
      "[GNN] Epoch 35/100 | TrainLoss=0.6830 | ValLoss=0.7264 | Val_R2=0.1891 | Val_MAE=0.7264\n",
      "[GNN] Epoch 36/100 | TrainLoss=0.6477 | ValLoss=0.7271 | Val_R2=0.2614 | Val_MAE=0.7271\n",
      "[GNN] Epoch 37/100 | TrainLoss=0.6562 | ValLoss=0.7141 | Val_R2=0.2373 | Val_MAE=0.7141\n",
      "[GNN] Epoch 38/100 | TrainLoss=0.6458 | ValLoss=0.6934 | Val_R2=0.3196 | Val_MAE=0.6934\n",
      "[GNN] Epoch 39/100 | TrainLoss=0.6375 | ValLoss=0.7491 | Val_R2=0.1593 | Val_MAE=0.7491\n",
      "[GNN] Epoch 40/100 | TrainLoss=0.6316 | ValLoss=0.6870 | Val_R2=0.2949 | Val_MAE=0.6870\n",
      "[GNN] Epoch 41/100 | TrainLoss=0.6364 | ValLoss=0.7167 | Val_R2=0.2368 | Val_MAE=0.7167\n",
      "[GNN] Epoch 42/100 | TrainLoss=0.6187 | ValLoss=0.7942 | Val_R2=0.1538 | Val_MAE=0.7942\n",
      "[GNN] Epoch 43/100 | TrainLoss=0.6321 | ValLoss=0.7694 | Val_R2=0.1657 | Val_MAE=0.7694\n",
      "[GNN] Epoch 44/100 | TrainLoss=0.6225 | ValLoss=0.7101 | Val_R2=0.2271 | Val_MAE=0.7101\n",
      "[GNN] Epoch 45/100 | TrainLoss=0.5958 | ValLoss=0.7173 | Val_R2=0.2537 | Val_MAE=0.7173\n",
      "[GNN] Epoch 46/100 | TrainLoss=0.6068 | ValLoss=0.7631 | Val_R2=0.0477 | Val_MAE=0.7631\n",
      "[GNN] Epoch 47/100 | TrainLoss=0.5863 | ValLoss=0.7877 | Val_R2=0.1310 | Val_MAE=0.7877\n",
      "[GNN] Epoch 48/100 | TrainLoss=0.6078 | ValLoss=0.7227 | Val_R2=0.2855 | Val_MAE=0.7227\n",
      "[GNN] Epoch 49/100 | TrainLoss=0.5990 | ValLoss=0.7240 | Val_R2=0.2250 | Val_MAE=0.7240\n",
      "[GNN] Epoch 50/100 | TrainLoss=0.5818 | ValLoss=0.7288 | Val_R2=0.1999 | Val_MAE=0.7288\n",
      "Early stopping at epoch 50 (no improvement in 10 epochs).\n",
      "\n",
      "✅ GNN Encoder restored to best checkpoint (Epoch=40, ValLoss=0.6870).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备:\", device)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred), mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "train_graph_dataset = GraphDataset(graph_list, train_idx_gnn)\n",
    "val_graph_dataset   = GraphDataset(graph_list, val_idx_gnn)\n",
    "\n",
    "ENC_BATCH_SIZE_G = 64\n",
    "MAX_EPOCHS_G     = 100\n",
    "PATIENCE_G       = 10\n",
    "LR_G             = 3e-3\n",
    "WEIGHT_DECAY_G   = 1e-4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_graph_dataset,\n",
    "    batch_size=ENC_BATCH_SIZE_G,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_graph_dataset,\n",
    "    batch_size=ENC_BATCH_SIZE_G,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "# 节点/边特征维度\n",
    "node_feat_dim = graph_list[0].x.size(-1)\n",
    "edge_feat_dim = graph_list[0].edge_attr.size(-1)\n",
    "\n",
    "gnn_model = GATv2Regressor(\n",
    "    in_channels=node_feat_dim,\n",
    "    hidden_channels=256,\n",
    "    num_layers=3,\n",
    "    heads=4,\n",
    "    edge_dim=edge_feat_dim,\n",
    "    dropout=0.05,\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(gnn_model.parameters(), lr=LR_G, weight_decay=WEIGHT_DECAY_G)\n",
    "\n",
    "steps_per_epoch = max(1, math.ceil(len(train_loader)))\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=LR_G,\n",
    "    epochs=MAX_EPOCHS_G,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    ")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state_dict = None\n",
    "best_epoch_g = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS_G + 1):\n",
    "    # ---- 训练 ----\n",
    "    gnn_model.train()\n",
    "    train_losses = []\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = gnn_model(batch)\n",
    "        y_true = batch.y.view(-1).to(device)\n",
    "        loss = torch.nn.functional.l1_loss(pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = float(np.mean(train_losses)) if train_losses else float(\"nan\")\n",
    "\n",
    "    # ---- 验证 ----\n",
    "    gnn_model.eval()\n",
    "    val_losses = []\n",
    "    val_true, val_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = gnn_model(batch)\n",
    "            y_true = batch.y.view(-1).to(device)\n",
    "            loss = torch.nn.functional.l1_loss(pred, y_true)\n",
    "            val_losses.append(loss.item())\n",
    "            val_true.append(y_true.cpu().numpy())\n",
    "            val_pred.append(pred.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = float(np.mean(val_losses)) if val_losses else float(\"nan\")\n",
    "    val_true = np.concatenate(val_true, axis=0)\n",
    "    val_pred = np.concatenate(val_pred, axis=0)\n",
    "    val_r2, val_mae = compute_metrics(val_true, val_pred)\n",
    "\n",
    "    print(\n",
    "        f\"[GNN] Epoch {epoch}/{MAX_EPOCHS_G} | \"\n",
    "        f\"TrainLoss={avg_train_loss:.4f} | \"\n",
    "        f\"ValLoss={avg_val_loss:.4f} | \"\n",
    "        f\"Val_R2={val_r2:.4f} | Val_MAE={val_mae:.4f}\"\n",
    "    )\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch_g = epoch\n",
    "        best_state_dict = {k: v.cpu().clone() for k, v in gnn_model.state_dict().items()}\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE_G:\n",
    "            print(f\"Early stopping at epoch {epoch} (no improvement in {PATIENCE_G} epochs).\")\n",
    "            break\n",
    "\n",
    "# 恢复最佳 checkpoint\n",
    "if best_state_dict is not None:\n",
    "    gnn_model.load_state_dict(best_state_dict)\n",
    "    gnn_model.to(device)\n",
    "    print(f\"\\n✅ GNN Encoder restored to best checkpoint (Epoch={best_epoch_g}, ValLoss={best_val_loss:.4f}).\")\n",
    "else:\n",
    "    print(\"\\n⚠️ 未记录到更优 checkpoint，当前权重即为最终权重。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80c25b-fcd3-4627-8267-b1466ef53250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d008893f-8d55-43e5-beb8-a146d5283798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_all shape: (3213, 256)\n",
      "row_id_graph_for_emb shape: (3213,)\n",
      "✅ 图嵌入与对应 row_id 已保存。\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "gnn_model.eval()\n",
    "\n",
    "all_embeds = []\n",
    "all_row_ids_for_emb = []\n",
    "\n",
    "full_loader = DataLoader(\n",
    "    graph_list,\n",
    "    batch_size=ENC_BATCH_SIZE_G,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in full_loader:\n",
    "        batch = batch.to(device)\n",
    "        graph_emb = gnn_model.encode_graph(batch)  # (B, hidden_dim)\n",
    "        all_embeds.append(graph_emb.cpu().numpy())\n",
    "        all_row_ids_for_emb.append(batch.row_id.view(-1).cpu().numpy())\n",
    "\n",
    "emb_all = np.concatenate(all_embeds, axis=0)               # (N_graph, d_g)\n",
    "row_id_graph_for_emb = np.concatenate(all_row_ids_for_emb, axis=0).astype(np.int64)\n",
    "\n",
    "print(\"emb_all shape:\", emb_all.shape)\n",
    "print(\"row_id_graph_for_emb shape:\", row_id_graph_for_emb.shape)\n",
    "\n",
    "np.save(GRAPH_EMB_PATH, emb_all)\n",
    "np.save(GRAPH_ROWID_EMB, row_id_graph_for_emb)\n",
    "\n",
    "print(\"✅ 图嵌入与对应 row_id 已保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5965f-9fdc-47f5-8abe-55bf3c28697d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc82faf2-12f2-4c44-b4dd-a2344ef30413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_all_g shape: (3213, 256)\n",
      "row_id_graph shape: (3213,)\n",
      "X_all_graph shape: (3213, 260)\n",
      "y_all_graph shape: (3213,)\n",
      "样本数一致吗？ True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 载入刚刚保存的嵌入\n",
    "emb_all_g = np.load(GRAPH_EMB_PATH)              # (N_graph, d_g)\n",
    "row_id_graph = np.load(GRAPH_ROWID_EMB)          # (N_graph,)\n",
    "\n",
    "print(\"emb_all_g shape:\", emb_all_g.shape)\n",
    "print(\"row_id_graph shape:\", row_id_graph.shape)\n",
    "\n",
    "df_indexed = df.set_index(\"row_id\")\n",
    "\n",
    "# 确保这些 row_id 都在 df 中\n",
    "assert set(row_id_graph).issubset(set(df_indexed.index)), \"有 row_id 不在 df 中，请检查预处理。\"\n",
    "\n",
    "meta_df = df_indexed.loc[row_id_graph, [\"Duration_Value(hour)\", \"Effect\", \"Endpoint\"]].copy()\n",
    "\n",
    "# ===== 这里改了：直接用原始 Duration，不做 log =====\n",
    "meta_df[\"Duration_raw\"] = meta_df[\"Duration_Value(hour)\"].astype(float)\n",
    "\n",
    "# 分类特征 one-hot\n",
    "effect_dum   = pd.get_dummies(meta_df[\"Effect\"], prefix=\"eff\")\n",
    "endpoint_dum = pd.get_dummies(meta_df[\"Endpoint\"], prefix=\"ep\")\n",
    "\n",
    "# 用 Duration_raw + one-hot(effect) + one-hot(endpoint)\n",
    "meta_feat_df = pd.concat(\n",
    "    [meta_df[[\"Duration_raw\"]], effect_dum, endpoint_dum],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "X_meta = meta_feat_df.values.astype(np.float32)\n",
    "X_graph = emb_all_g.astype(np.float32)\n",
    "\n",
    "X_all_graph = np.concatenate([X_graph, X_meta], axis=1)\n",
    "\n",
    "y_all_graph = df_indexed.loc[row_id_graph, \"mgperL_log\"].values.astype(np.float32)\n",
    "smiles_all_graph = df_indexed.loc[row_id_graph, \"SMILES_Canonical_RDKit\"].values\n",
    "\n",
    "print(\"X_all_graph shape:\", X_all_graph.shape)\n",
    "print(\"y_all_graph shape:\", y_all_graph.shape)\n",
    "print(\"样本数一致吗？\", X_all_graph.shape[0] == y_all_graph.shape[0] == len(smiles_all_graph))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3fe0ea-22d7-4610-8281-39fe320d680d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f6c5f8-bbd8-48a2-b8a3-a8fbceb0d00b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train 样本数: 2581\n",
      "RF test  样本数: 632\n",
      "\n",
      "==== 开始在 RF(train) 上做十折随机搜索 (GroupKFold) ====\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 4.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.4min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.8min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=13.5min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.0min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.6min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.6min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=26.5min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.5min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=12.6min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=12.9min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.5min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 5.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.7min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.2min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=11.8min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=19.1min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 4.0min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 2.0min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.5min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.3min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=13.2min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=13.0min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  11.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  29.2s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  45.0s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.5min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 4.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.2min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.8min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.7min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=12.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=17.8min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.7min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.5min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=13.5min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=14.7min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=12.0min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.1min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=11.8min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=18.2min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.7min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.3min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 5.1min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 4.8min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=14.0min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  13.0s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  47.1s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  45.3s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.5min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 3.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.0min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.4min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.9min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.6min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=11.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=17.9min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 4.8min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.1min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.4min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.8min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=13.3min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=13.4min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  25.0s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  47.7s\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=11.8min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.7min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=13.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.3min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.6min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 2.6min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=25.9min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=13.5min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=16.0min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  23.0s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  48.5s\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.1min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.0min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 2.9min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=12.7min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=11.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=17.7min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=23.9min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 5.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=14.3min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=13.7min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  22.5s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  49.9s\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=11.8min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.7min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=13.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.5min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.7min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 2.0min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=25.2min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.5min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 4.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=14.0min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=13.5min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 4.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.0min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.5min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.6min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=11.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=18.3min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=26.1min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 4.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=15.7min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=12.4min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.2min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.6min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 5.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.4min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.6min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.9min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=12.5min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=17.8min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.2min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.4min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 1.7min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 2.1min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.1min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.8min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.5min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.4min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 5.1min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=14.9min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=12.5min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  23.8s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  48.8s\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.3min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=12.1min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.7min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=11.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.5min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 2.7min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=23.6min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 3.9min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 4.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 5.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=12.9min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=11.2min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.9min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=12.2min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.8min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=13.1min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=18.6min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.9min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.9min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 1.6min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 2.1min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.1min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 5.8min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=14.9min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=12.6min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.2min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.0min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 3.1min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=13.1min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.5min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=12.9min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=17.8min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.6min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 2.1min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.6min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=240; total time= 1.5min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=5, n_estimators=232; total time= 5.4min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=16.4min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=12.6min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=508; total time= 2.3min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=12.0min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.5min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=12.6min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=24.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.0min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=13.7min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=12.6min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=11.3min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.4min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 4.1min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=12.3min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 2.0min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=11.6min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=14.9min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=25.7min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=13.7min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=12.9min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=11.4min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  20.8s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  49.9s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  49.4s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 3.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 3.6min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.7min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=13.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=902; total time= 3.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.6min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=469; total time= 1.6min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=25.0min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=698; total time= 3.1min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=12.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=13.9min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=11.6min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=1, min_samples_split=10, n_estimators=306; total time= 1.3min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.3min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=659; total time= 3.8min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=886; total time=12.7min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=539; total time= 1.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=10.9min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=761; total time=15.1min\n",
      "[CV] END max_depth=20, max_features=0.5, min_samples_leaf=4, min_samples_split=5, n_estimators=926; total time=25.6min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=14.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=746; total time=12.9min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=12.1min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  10.7s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=321; total time=  30.3s\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=10, n_estimators=287; total time=  48.7s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=585; total time= 2.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=760; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=675; total time= 5.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=330; total time= 3.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=366; total time= 4.0min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=441; total time= 5.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=2, n_estimators=975; total time=12.9min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=589; total time=18.3min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=919; total time= 5.6min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=991; total time= 3.5min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 1.9min\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=356; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=720; total time= 4.5min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=4, min_samples_split=10, n_estimators=488; total time=12.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=927; total time=15.3min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=1, min_samples_split=10, n_estimators=661; total time=12.4min\n",
      "\n",
      "===== RF 最优超参（train 上 10-fold GroupKFold）=====\n",
      "{'max_depth': 30, 'max_features': 0.3, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 975}\n",
      "CV 平均 R^2: 0.4889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr, randint\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# ===== 1) SMILES 分组的 8:2 划分（RF 自己一套，与 GNN 划分独立）=====\n",
    "groups = smiles_all_graph  # group 标签就是 SMILES\n",
    "\n",
    "gss_rf = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=2025)\n",
    "train_idx_rf, test_idx_rf = next(gss_rf.split(X_all_graph, y_all_graph, groups=groups))\n",
    "\n",
    "train_idx_rf = np.array(train_idx_rf, dtype=np.int64)\n",
    "test_idx_rf  = np.array(test_idx_rf, dtype=np.int64)\n",
    "\n",
    "X_train_rf = X_all_graph[train_idx_rf]\n",
    "X_test_rf  = X_all_graph[test_idx_rf]\n",
    "y_train_rf = y_all_graph[train_idx_rf]\n",
    "y_test_rf  = y_all_graph[test_idx_rf]\n",
    "groups_train_rf = groups[train_idx_rf]\n",
    "\n",
    "print(\"RF train 样本数:\", X_train_rf.shape[0])\n",
    "print(\"RF test  样本数:\", X_test_rf.shape[0])\n",
    "\n",
    "# ===== 2) 在 train 集上做十折 GroupKFold + RandomizedSearchCV 找超参 =====\n",
    "base_rf = RandomForestRegressor(\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    \"n_estimators\": randint(200, 1001),        # [200, 1000]\n",
    "    \"max_depth\": [None, 10, 20, 30],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.3, 0.5],\n",
    "}\n",
    "\n",
    "# 固定一套十折划分，后面 OOF 也用同一套\n",
    "cv_inner = GroupKFold(n_splits=10)\n",
    "cv_indices_graph = list(cv_inner.split(X_train_rf, y_train_rf, groups_train_rf))\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=base_rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    scoring=\"r2\",\n",
    "    cv=cv_indices_graph,   # 用固定 folds\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"\\n==== 开始在 RF(train) 上做十折随机搜索 (GroupKFold) ====\")\n",
    "rf_search.fit(X_train_rf, y_train_rf, groups=groups_train_rf)\n",
    "\n",
    "best_params_rf = rf_search.best_params_\n",
    "best_cv_score  = rf_search.best_score_\n",
    "\n",
    "print(\"\\n===== RF 最优超参（train 上 10-fold GroupKFold）=====\")\n",
    "print(best_params_rf)\n",
    "print(f\"CV 平均 R^2: {best_cv_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563112d-2421-4c5b-8023-55d5063824cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b3c933c-4ecb-47de-9aea-dfca7d4d6d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== 基于最优超参，在同一套 10 折上计算 train OOF 预测 ====\n",
      "  -> OOF fold 1 / 10\n",
      "  -> OOF fold 2 / 10\n",
      "  -> OOF fold 3 / 10\n",
      "  -> OOF fold 4 / 10\n",
      "  -> OOF fold 5 / 10\n",
      "  -> OOF fold 6 / 10\n",
      "  -> OOF fold 7 / 10\n",
      "  -> OOF fold 8 / 10\n",
      "  -> OOF fold 9 / 10\n",
      "  -> OOF fold 10 / 10\n",
      "\n",
      "===== RF 图像端：train OOF 表现 =====\n",
      "r2: 0.4946\n",
      "mae: 0.6001\n",
      "rmse: 0.8184\n",
      "r: 0.7040\n",
      "\n",
      "===== RF 训练集表现 =====\n",
      "r2: 0.8871\n",
      "mae: 0.2670\n",
      "rmse: 0.3869\n",
      "r: 0.9498\n",
      "\n",
      "===== RF 测试集表现（独立 20% SMILES 组）=====\n",
      "r2: 0.5074\n",
      "mae: 0.6145\n",
      "rmse: 0.8497\n",
      "r: 0.7138\n",
      "\n",
      "✅ RF 图像端：模型、指标、OOF、预测和索引已保存到: /root/Invertebrates_EC50_multi_fusion/graph/graph_outputs\n",
      "   - rf_graph_oof_pred_train.npy  (train OOF，用于 late fusion)\n",
      "   - rf_graph_y_pred_test.npy     (test 预测，用于 late fusion)\n",
      "   - rf_graph_train_idx.npy / rf_graph_test_idx.npy (与文本端对齐的 8:2 划分)\n"
     ]
    }
   ],
   "source": [
    "# ===== 一些小工具 =====\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"r2\": r2_score(y_true, y_pred),\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"r\": pearsonr(y_true, y_pred)[0],\n",
    "    }\n",
    "\n",
    "# ===== 3) 用同一套 10 折 + 最优超参，算 train OOF 预测 =====\n",
    "print(\"\\n==== 基于最优超参，在同一套 10 折上计算 train OOF 预测 ====\")\n",
    "\n",
    "oof_pred_train_rf = np.zeros_like(y_train_rf, dtype=float)\n",
    "\n",
    "for fold_idx, (tr_idx, val_idx) in enumerate(cv_indices_graph, 1):\n",
    "    print(f\"  -> OOF fold {fold_idx} / {len(cv_indices_graph)}\")\n",
    "    rf_fold = RandomForestRegressor(\n",
    "        **best_params_rf,\n",
    "        n_jobs=-1,\n",
    "        random_state=42 + fold_idx,\n",
    "    )\n",
    "    rf_fold.fit(X_train_rf[tr_idx], y_train_rf[tr_idx])\n",
    "    oof_pred_train_rf[val_idx] = rf_fold.predict(X_train_rf[val_idx])\n",
    "\n",
    "metrics_oof = regression_metrics(y_train_rf, oof_pred_train_rf)\n",
    "\n",
    "print(\"\\n===== RF 图像端：train OOF 表现 =====\")\n",
    "for k, v in metrics_oof.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ===== 4) 用最优超参在整个 train80% 上拟合最终 RF =====\n",
    "best_rf = RandomForestRegressor(\n",
    "    **best_params_rf,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "best_rf.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "y_pred_train = best_rf.predict(X_train_rf)\n",
    "y_pred_test  = best_rf.predict(X_test_rf)\n",
    "\n",
    "metrics_train = regression_metrics(y_train_rf, y_pred_train)\n",
    "metrics_test  = regression_metrics(y_test_rf, y_pred_test)\n",
    "\n",
    "print(\"\\n===== RF 训练集表现 =====\")\n",
    "for k, v in metrics_train.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n===== RF 测试集表现（独立 20% SMILES 组）=====\")\n",
    "for k, v in metrics_test.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ===== 5) 保存模型 & 指标 & 划分索引 & OOF / 预测（用于后期融合）=====\n",
    "RF_MODEL_PATH   = GRAPH_OUT_DIR / \"rf_graph_model.pkl\"\n",
    "RF_METRICS_PATH = GRAPH_OUT_DIR / \"rf_graph_metrics.json\"\n",
    "RF_PARAMS_PATH  = GRAPH_OUT_DIR / \"rf_graph_best_params.json\"\n",
    "RF_SPLIT_PATH   = GRAPH_OUT_DIR / \"rf_graph_train_test_idx.npz\"\n",
    "\n",
    "with open(RF_MODEL_PATH, \"wb\") as f:\n",
    "    pickle.dump(best_rf, f)\n",
    "\n",
    "# 指标里加上 oof 一块存\n",
    "with open(RF_METRICS_PATH, \"w\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"train\": metrics_train,\n",
    "            \"test\":  metrics_test,\n",
    "            \"oof\":   metrics_oof,\n",
    "            \"cv_best_r2\": float(best_cv_score),\n",
    "        },\n",
    "        f,\n",
    "        indent=2\n",
    "    )\n",
    "\n",
    "with open(RF_PARAMS_PATH, \"w\") as f:\n",
    "    json.dump(best_params_rf, f, indent=2)\n",
    "\n",
    "# 保存 8:2 的索引（原来就有）\n",
    "np.savez(\n",
    "    RF_SPLIT_PATH,\n",
    "    train_idx=train_idx_rf,\n",
    "    test_idx=test_idx_rf,\n",
    ")\n",
    "\n",
    "# 🔹新增：给后期融合用的关键文件（命名跟文本端保持风格一致）\n",
    "np.save(GRAPH_OUT_DIR / \"rf_graph_y_train.npy\",        y_train_rf.astype(np.float32))\n",
    "np.save(GRAPH_OUT_DIR / \"rf_graph_y_test.npy\",         y_test_rf.astype(np.float32))\n",
    "np.save(GRAPH_OUT_DIR / \"rf_graph_oof_pred_train.npy\", oof_pred_train_rf.astype(np.float32))\n",
    "np.save(GRAPH_OUT_DIR / \"rf_graph_y_pred_test.npy\",    y_pred_test.astype(np.float32))\n",
    "np.save(GRAPH_OUT_DIR / \"rf_graph_train_idx.npy\",      train_idx_rf.astype(np.int64))\n",
    "np.save(GRAPH_OUT_DIR / \"rf_graph_test_idx.npy\",       test_idx_rf.astype(np.int64))\n",
    "\n",
    "print(\"\\n✅ RF 图像端：模型、指标、OOF、预测和索引已保存到:\", GRAPH_OUT_DIR)\n",
    "print(\"   - rf_graph_oof_pred_train.npy  (train OOF，用于 late fusion)\")\n",
    "print(\"   - rf_graph_y_pred_test.npy     (test 预测，用于 late fusion)\")\n",
    "print(\"   - rf_graph_train_idx.npy / rf_graph_test_idx.npy (与文本端对齐的 8:2 划分)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ecf71-0428-41e4-8001-a04e67055306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306852f-3ecc-47bf-87b4-86a5a3b637c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e8310d-43e7-413c-b9dc-8526e55812bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
