{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773f4e47-f119-468e-9f19-9e2303f8bc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 1: 依赖 & 工具函数 =====\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import joblib\n",
    "\n",
    "# ---- 全局随机种子 ----\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备:\", device)\n",
    "\n",
    "\n",
    "def compute_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"计算 MAE / RMSE / R2 / Pearson_r\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "\n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        pr = float(\"nan\")\n",
    "    else:\n",
    "        pr, _ = pearsonr(y_true, y_pred)\n",
    "        pr = float(pr)\n",
    "\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"Pearson_r\": pr}\n",
    "\n",
    "\n",
    "def np_encoder(o):\n",
    "    if isinstance(o, (np.integer,)):\n",
    "        return int(o)\n",
    "    if isinstance(o, (np.floating,)):\n",
    "        return float(o)\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    raise TypeError(f\"Type {type(o)} not serializable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523fafe-a768-4276-8809-7c07dc54e08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046eb4a0-c686-4013-9895-9b2b8640c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT_EMB_768: /root/Invertebrates_EC50_multi_fusion/SMILES/smiles_outputs/reg_smiles_cls_embeddings_all.npy\n",
      "PHY_EMB_PATH: /root/Invertebrates_EC50_multi_fusion/phychem/physchem_mlp_rf_v2/emb_physchem_mlp_all.npy\n",
      "DATA_PATH   : /root/fusion_dataset/with_physchem_excels/Invertebrates_EC50_unique_physchem.xlsx\n",
      "OUT_TP      : /root/Invertebrates_EC50_multi_fusion/mid(T+P)/text_physchem_meta\n",
      "df 形状: (3620, 36)\n",
      "   row_id    SMILES_Canonical_RDKit  mgperL  mgperL_log\n",
      "0       0        [Cl-].[Cl-].[Zn+2]     1.3    0.113943\n",
      "1       1  O=S(=O)([O-])[O-].[Zn+2]     2.5    0.397940\n",
      "2       2        [Cl-].[Cl-].[Pb+2]    40.8    1.610660\n",
      "3       3  O=S(=O)([O-])[O-].[Cu+2]     1.9    0.278754\n",
      "4       4  O=S(=O)([O-])[O-].[Cu+2]     0.6   -0.221849\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: 路径 & 读取 df =====\n",
    "ROOT_MULTI = Path(\"/root/Invertebrates_EC50_multi_fusion\")\n",
    "\n",
    "# Text CLS 嵌入\n",
    "TEXT_DIR     = ROOT_MULTI / \"SMILES\" / \"smiles_outputs\"\n",
    "TEXT_EMB_768 = TEXT_DIR / \"reg_smiles_cls_embeddings_all.npy\"\n",
    "\n",
    "# PhysChem MLP 嵌入 + row_id\n",
    "PHY_DIR        = ROOT_MULTI / \"phychem\" / \"physchem_mlp_rf_v2\"\n",
    "PHY_EMB_PATH   = PHY_DIR / \"emb_physchem_mlp_all.npy\"\n",
    "PHY_ROWID_PATH = PHY_DIR / \"row_id_clean.npy\"\n",
    "\n",
    "# 原始数据\n",
    "DATA_PATH = Path(\"/root/fusion_dataset/with_physchem_excels/Invertebrates_EC50_unique_physchem.xlsx\")\n",
    "\n",
    "# 输出目录\n",
    "MID_ROOT   = ROOT_MULTI / \"mid(T+P)\"\n",
    "OUT_TP     = MID_ROOT / \"text_physchem_meta\"\n",
    "MODELS_CA  = OUT_TP / \"models_crossattn\"\n",
    "MODELS_RF  = OUT_TP / \"models_rf\"\n",
    "for d in [MID_ROOT, OUT_TP, MODELS_CA, MODELS_RF]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 列名\n",
    "SMILES_COL   = \"SMILES_Canonical_RDKit\"\n",
    "DURATION_COL = \"Duration_Value(hour)\"\n",
    "EFFECT_COL   = \"Effect\"\n",
    "ENDPOINT_COL = \"Endpoint\"\n",
    "LABEL_RAW    = \"mgperL\"\n",
    "LABEL_LOG    = \"mgperL_log\"\n",
    "LABEL_COL    = LABEL_LOG\n",
    "\n",
    "print(\"TEXT_EMB_768:\", TEXT_EMB_768)\n",
    "print(\"PHY_EMB_PATH:\", PHY_EMB_PATH)\n",
    "print(\"DATA_PATH   :\", DATA_PATH)\n",
    "print(\"OUT_TP      :\", OUT_TP)\n",
    "\n",
    "# 读取 df\n",
    "df = pd.read_excel(DATA_PATH, engine=\"openpyxl\")\n",
    "if \"row_id\" not in df.columns:\n",
    "    df = df.reset_index().rename(columns={\"index\": \"row_id\"})\n",
    "df[\"row_id\"] = df[\"row_id\"].astype(int)\n",
    "\n",
    "# 构造 mgperL_log（如需）\n",
    "if LABEL_LOG not in df.columns:\n",
    "    df[LABEL_RAW] = pd.to_numeric(df[LABEL_RAW], errors=\"coerce\")\n",
    "    mask_valid = df[LABEL_RAW] > 0\n",
    "    df[LABEL_LOG] = np.where(mask_valid, np.log10(df[LABEL_RAW]), np.nan)\n",
    "\n",
    "print(\"df 形状:\", df.shape)\n",
    "print(df[[\"row_id\", SMILES_COL, LABEL_RAW, LABEL_LOG]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5262a-0c47-4df5-b13b-a97ef0bb9d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565abba5-4d9b-43e8-aa42-3027ab9650f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_all_full 形状: (3620, 768)\n",
      "phys_emb 形状: (3406, 64)\n",
      "rowid_phys 范围: 0 → 3619\n",
      "Text+Phys row_id 交集初始样本数: 3406\n",
      "过滤后样本数: 3406\n",
      "X_text  形状: (3406, 768)\n",
      "X_phys  形状: (3406, 64)\n",
      "dur_raw 形状: (3406, 1)\n",
      "cat_all 形状: (3406, 3)\n",
      "总样本数 N: 3406\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 3: 加载 Text & PhysChem，对齐 + 构造 meta =====\n",
    "\n",
    "# Text：CLS 按 df 行号对齐\n",
    "text_all_full = np.load(TEXT_EMB_768)\n",
    "assert text_all_full.shape[0] == len(df), \"text_all_full 行数应与 df 行数一致\"\n",
    "print(\"text_all_full 形状:\", text_all_full.shape)\n",
    "\n",
    "# PhysChem\n",
    "phys_emb   = np.load(PHY_EMB_PATH)\n",
    "rowid_phys = np.load(PHY_ROWID_PATH).astype(int)\n",
    "print(\"phys_emb 形状:\", phys_emb.shape)\n",
    "print(\"rowid_phys 范围:\", rowid_phys.min(), \"→\", rowid_phys.max())\n",
    "\n",
    "df_indexed = df.set_index(\"row_id\")\n",
    "\n",
    "ids_text = set(df_indexed.index.tolist())   # text 按 df 行号\n",
    "ids_phys = set(rowid_phys.tolist())\n",
    "ids_all  = set(df_indexed.index.tolist())\n",
    "\n",
    "ids_inter = sorted(list(ids_text & ids_phys & ids_all))\n",
    "print(\"Text+Phys row_id 交集初始样本数:\", len(ids_inter))\n",
    "\n",
    "idx_map_phys = {rid: i for i, rid in enumerate(rowid_phys)}\n",
    "\n",
    "meta_list    = []\n",
    "X_text_list  = []\n",
    "X_phys_list  = []\n",
    "y_list       = []\n",
    "rid_list     = []\n",
    "\n",
    "for rid in ids_inter:\n",
    "    row_meta = df_indexed.loc[rid]\n",
    "    label = row_meta[LABEL_COL]\n",
    "    # 要求标签 & meta 都存在\n",
    "    if pd.isna(label) or not np.isfinite(label):\n",
    "        continue\n",
    "    if pd.isna(row_meta.get(DURATION_COL)) or pd.isna(row_meta.get(EFFECT_COL)) or pd.isna(row_meta.get(ENDPOINT_COL)):\n",
    "        continue\n",
    "\n",
    "    meta_list.append(row_meta)\n",
    "    X_text_list.append(text_all_full[rid])                      # Text 直接用 row_id 索引\n",
    "    X_phys_list.append(phys_emb[idx_map_phys[rid]])             # PhysChem 用 rowid_phys 映射\n",
    "    y_list.append(label)\n",
    "    rid_list.append(rid)\n",
    "\n",
    "meta_tp  = pd.DataFrame(meta_list).reset_index(drop=True)\n",
    "X_text   = np.stack(X_text_list, axis=0)\n",
    "X_phys   = np.stack(X_phys_list, axis=0)\n",
    "y_all    = np.array(y_list, dtype=float)\n",
    "rowid_all= np.array(rid_list, dtype=int)\n",
    "\n",
    "print(\"过滤后样本数:\", len(y_all))\n",
    "print(\"X_text  形状:\", X_text.shape)\n",
    "print(\"X_phys  形状:\", X_phys.shape)\n",
    "\n",
    "# ========== 构造 meta：Duration + Effect/Endpoint one-hot ==========\n",
    "# Duration\n",
    "meta_tp[DURATION_COL] = pd.to_numeric(meta_tp[DURATION_COL], errors=\"coerce\")\n",
    "dur_median = meta_tp[DURATION_COL].median()\n",
    "meta_tp[DURATION_COL] = meta_tp[DURATION_COL].fillna(dur_median)\n",
    "dur_raw = meta_tp[[DURATION_COL]].values.astype(float)  # (N, 1)\n",
    "\n",
    "# One-hot: Effect + Endpoint\n",
    "cat_cols = [EFFECT_COL, ENDPOINT_COL]\n",
    "cat_dummies = pd.get_dummies(meta_tp[cat_cols], dummy_na=False)\n",
    "cat_all = cat_dummies.values.astype(float)\n",
    "cat_feature_names = list(cat_dummies.columns)\n",
    "\n",
    "print(\"dur_raw 形状:\", dur_raw.shape)\n",
    "print(\"cat_all 形状:\", cat_all.shape)\n",
    "\n",
    "# 分组（按 SMILES）\n",
    "groups_all = meta_tp[SMILES_COL].astype(str).values\n",
    "print(\"总样本数 N:\", len(y_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd65126-70ff-4210-8ae5-ec3194b830d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87581e54-831e-44c9-8257-a225966675ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_text_raw 形状: (3406, 768)\n",
      "X_phys_raw 形状: (3406, 64)\n",
      "dur_raw    形状: (3406, 1)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 4: 原始数值块 =====\n",
    "X_text_raw = X_text      # (N, d_text)\n",
    "X_phys_raw = X_phys      # (N, d_phys)\n",
    "print(\"X_text_raw 形状:\", X_text_raw.shape)\n",
    "print(\"X_phys_raw 形状:\", X_phys_raw.shape)\n",
    "print(\"dur_raw    形状:\", dur_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876233d-f337-42a7-bd0f-52848b52fd16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c8581e-5ffd-431f-8af9-e081b698d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5: Dataset & Cross-Attn 模型（Text+Phys） =====\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, X1, X2, y):\n",
    "        self.X1 = torch.from_numpy(X1).float()\n",
    "        self.X2 = torch.from_numpy(X2).float()\n",
    "        self.y  = torch.from_numpy(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class CrossAttnEncoder(nn.Module):\n",
    "    \"\"\"两模态编码，输出融合 embedding\"\"\"\n",
    "    def __init__(self, dim_a, dim_b, hidden_dim=256, num_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.proj_a = nn.Linear(dim_a, hidden_dim)\n",
    "        self.proj_b = nn.Linear(dim_b, hidden_dim)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=False,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, xa, xb):\n",
    "        # xa, xb: (B, d_a/d_b)\n",
    "        h_a = self.proj_a(xa)  # (B, hidden)\n",
    "        h_b = self.proj_b(xb)  # (B, hidden)\n",
    "        tokens = torch.stack([h_a, h_b], dim=0)  # (2, B, hidden)\n",
    "        attn_out, _ = self.attn(tokens, tokens, tokens)  # (2, B, hidden)\n",
    "        fused = attn_out.mean(dim=0)  # (B, hidden)\n",
    "        return self.dropout(fused)\n",
    "\n",
    "\n",
    "class CrossAttnWithHead(nn.Module):\n",
    "    \"\"\"Encoder + 小回归头，用于训练 encoder\"\"\"\n",
    "    def __init__(self, dim_a, dim_b,\n",
    "                 hidden_dim=256,\n",
    "                 num_heads=4,\n",
    "                 mlp_hidden=512,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = CrossAttnEncoder(dim_a, dim_b, hidden_dim, num_heads, dropout)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, xa, xb):\n",
    "        fused = self.encoder(xa, xb)          # (B, hidden)\n",
    "        out   = self.head(fused).squeeze(-1)  # (B,)\n",
    "        return out, fused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b43152-c670-4897-a528-33691638f3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6bc1a94-5645-473c-966d-283641c6591a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Attn T+P train 样本数: 2733\n",
      "Cross-Attn T+P val   样本数: 673\n",
      "X_text_ca_train 形状: (2733, 768)\n",
      "X_phys_ca_train 形状: (2733, 64)\n",
      "[Cross-Attn T+P] Epoch 001 | train MAE = 0.6539, val MAE = 0.5834\n",
      "[Cross-Attn T+P] Epoch 002 | train MAE = 0.5431, val MAE = 0.5475\n",
      "[Cross-Attn T+P] Epoch 003 | train MAE = 0.5246, val MAE = 0.5570\n",
      "[Cross-Attn T+P] Epoch 004 | train MAE = 0.5075, val MAE = 0.5505\n",
      "[Cross-Attn T+P] Epoch 005 | train MAE = 0.5089, val MAE = 0.5365\n",
      "[Cross-Attn T+P] Epoch 006 | train MAE = 0.4982, val MAE = 0.5476\n",
      "[Cross-Attn T+P] Epoch 007 | train MAE = 0.5011, val MAE = 0.5606\n",
      "[Cross-Attn T+P] Epoch 008 | train MAE = 0.4968, val MAE = 0.5277\n",
      "[Cross-Attn T+P] Epoch 009 | train MAE = 0.4822, val MAE = 0.5305\n",
      "[Cross-Attn T+P] Epoch 010 | train MAE = 0.4894, val MAE = 0.5272\n",
      "[Cross-Attn T+P] Epoch 011 | train MAE = 0.4773, val MAE = 0.5417\n",
      "[Cross-Attn T+P] Epoch 012 | train MAE = 0.4751, val MAE = 0.5585\n",
      "[Cross-Attn T+P] Epoch 013 | train MAE = 0.4662, val MAE = 0.5431\n",
      "[Cross-Attn T+P] Epoch 014 | train MAE = 0.4614, val MAE = 0.5521\n",
      "[Cross-Attn T+P] Epoch 015 | train MAE = 0.4566, val MAE = 0.5586\n",
      "[Cross-Attn T+P] Epoch 016 | train MAE = 0.4581, val MAE = 0.5372\n",
      "[Cross-Attn T+P] Epoch 017 | train MAE = 0.4563, val MAE = 0.5753\n",
      "[Cross-Attn T+P] Epoch 018 | train MAE = 0.4534, val MAE = 0.5374\n",
      "[Cross-Attn T+P] Epoch 019 | train MAE = 0.4401, val MAE = 0.5221\n",
      "[Cross-Attn T+P] Epoch 020 | train MAE = 0.4455, val MAE = 0.5520\n",
      "[Cross-Attn T+P] Epoch 021 | train MAE = 0.4468, val MAE = 0.5393\n",
      "[Cross-Attn T+P] Epoch 022 | train MAE = 0.4352, val MAE = 0.5307\n",
      "[Cross-Attn T+P] Epoch 023 | train MAE = 0.4366, val MAE = 0.5595\n",
      "[Cross-Attn T+P] Epoch 024 | train MAE = 0.4326, val MAE = 0.5408\n",
      "[Cross-Attn T+P] Epoch 025 | train MAE = 0.4298, val MAE = 0.5454\n",
      "[Cross-Attn T+P] Epoch 026 | train MAE = 0.4275, val MAE = 0.5477\n",
      "[Cross-Attn T+P] Epoch 027 | train MAE = 0.4250, val MAE = 0.5371\n",
      "[Cross-Attn T+P] Epoch 028 | train MAE = 0.4194, val MAE = 0.5493\n",
      "[Cross-Attn T+P] Epoch 029 | train MAE = 0.4223, val MAE = 0.5456\n",
      "[Cross-Attn T+P] Early stopping at epoch 29, best_epoch = 19\n",
      "fused_all_TP 形状: (3406, 256)\n",
      "\n",
      "✅ Cross-Attn (Text+Phys) 训练完成，fused_all_T_P 已保存。\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 6: Cross-Attn 按 SMILES 8:2 划分 & 训练（Text+Phys） =====\n",
    "\n",
    "# 1) Cross-Attn 自己的 8:2 划分（按 SMILES 分组）\n",
    "gss_ca = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=3025)\n",
    "N = len(y_all)\n",
    "idx_all = np.arange(N)\n",
    "\n",
    "ca_train_idx, ca_val_idx = next(\n",
    "    gss_ca.split(np.zeros(N), y_all, groups_all)\n",
    ")\n",
    "ca_train_idx = np.array(ca_train_idx, dtype=np.int64)\n",
    "ca_val_idx   = np.array(ca_val_idx, dtype=np.int64)\n",
    "\n",
    "print(\"Cross-Attn T+P train 样本数:\", len(ca_train_idx))\n",
    "print(\"Cross-Attn T+P val   样本数:\", len(ca_val_idx))\n",
    "\n",
    "np.save(OUT_TP / \"ca_train_idx_T_P.npy\", ca_train_idx)\n",
    "np.save(OUT_TP / \"ca_val_idx_T_P.npy\",   ca_val_idx)\n",
    "\n",
    "# 2) 在 Cross-Attn train80% 上拟合 Text / Phys 的 scaler\n",
    "scaler_text_ca = StandardScaler().fit(X_text_raw[ca_train_idx])\n",
    "scaler_phys_ca = StandardScaler().fit(X_phys_raw[ca_train_idx])\n",
    "\n",
    "X_text_ca_all_std = scaler_text_ca.transform(X_text_raw)\n",
    "X_phys_ca_all_std = scaler_phys_ca.transform(X_phys_raw)\n",
    "\n",
    "X_text_ca_train = X_text_ca_all_std[ca_train_idx]\n",
    "X_phys_ca_train = X_phys_ca_all_std[ca_train_idx]\n",
    "y_ca_train      = y_all[ca_train_idx]\n",
    "\n",
    "X_text_ca_val = X_text_ca_all_std[ca_val_idx]\n",
    "X_phys_ca_val = X_phys_ca_all_std[ca_val_idx]\n",
    "y_ca_val      = y_all[ca_val_idx]\n",
    "\n",
    "print(\"X_text_ca_train 形状:\", X_text_ca_train.shape)\n",
    "print(\"X_phys_ca_train 形状:\", X_phys_ca_train.shape)\n",
    "\n",
    "# 3) DataLoader\n",
    "batch_size = 64\n",
    "ds_ca_tr  = PairDataset(X_text_ca_train, X_phys_ca_train, y_ca_train)\n",
    "ds_ca_val = PairDataset(X_text_ca_val,   X_phys_ca_val,   y_ca_val)\n",
    "\n",
    "dl_ca_tr  = DataLoader(ds_ca_tr,  batch_size=batch_size, shuffle=True,  drop_last=False)\n",
    "dl_ca_val = DataLoader(ds_ca_val, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# 4) 定义 Cross-Attn 模型\n",
    "dim_a = X_text_ca_train.shape[1]\n",
    "dim_b = X_phys_ca_train.shape[1]\n",
    "\n",
    "model_ca = CrossAttnWithHead(\n",
    "    dim_a=dim_a,\n",
    "    dim_b=dim_b,\n",
    "    hidden_dim=256,\n",
    "    num_heads=4,\n",
    "    mlp_hidden=512,\n",
    "    dropout=0.1,\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_ca.parameters(),\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "max_epochs = 80\n",
    "patience   = 10\n",
    "best_val_mae = float(\"inf\")\n",
    "best_state_dict = None\n",
    "best_epoch = -1\n",
    "epochs_no_improve = 0\n",
    "\n",
    "history_ca = {\"train_mae\": [], \"val_mae\": []}\n",
    "\n",
    "# 5) 训练（val 做 early stopping）\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    model_ca.train()\n",
    "    train_abs_err = []\n",
    "\n",
    "    for X1_b, X2_b, y_b in dl_ca_tr:\n",
    "        X1_b = X1_b.to(device)\n",
    "        X2_b = X2_b.to(device)\n",
    "        y_b  = y_b.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_hat, fused = model_ca(X1_b, X2_b)\n",
    "        loss = loss_fn(y_hat, y_b)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_ca.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_abs_err.append(torch.abs(y_hat.detach() - y_b).cpu().numpy())\n",
    "\n",
    "    train_mae = float(np.mean(np.concatenate(train_abs_err)))\n",
    "    history_ca[\"train_mae\"].append(train_mae)\n",
    "\n",
    "    model_ca.eval()\n",
    "    val_abs_err = []\n",
    "    with torch.no_grad():\n",
    "        for X1_b, X2_b, y_b in dl_ca_val:\n",
    "            X1_b = X1_b.to(device)\n",
    "            X2_b = X2_b.to(device)\n",
    "            y_b  = y_b.to(device)\n",
    "\n",
    "            y_hat, fused = model_ca(X1_b, X2_b)\n",
    "            val_abs_err.append(torch.abs(y_hat - y_b).cpu().numpy())\n",
    "\n",
    "    val_mae = float(np.mean(np.concatenate(val_abs_err)))\n",
    "    history_ca[\"val_mae\"].append(val_mae)\n",
    "\n",
    "    print(f\"[Cross-Attn T+P] Epoch {epoch:03d} | train MAE = {train_mae:.4f}, val MAE = {val_mae:.4f}\")\n",
    "\n",
    "    if val_mae < best_val_mae - 1e-4:\n",
    "        best_val_mae = val_mae\n",
    "        best_state_dict = {k: v.cpu().clone() for k, v in model_ca.state_dict().items()}\n",
    "        best_epoch = epoch\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"[Cross-Attn T+P] Early stopping at epoch {epoch}, best_epoch = {best_epoch}\")\n",
    "            break\n",
    "\n",
    "# 6) 加载最佳权重，抽 fused_all_T_P\n",
    "if best_state_dict is not None:\n",
    "    model_ca.load_state_dict(best_state_dict)\n",
    "model_ca.to(device)\n",
    "model_ca.eval()\n",
    "\n",
    "encoder_tp = model_ca.encoder\n",
    "encoder_tp.eval().to(device)\n",
    "\n",
    "ds_all_ca = PairDataset(X_text_ca_all_std, X_phys_ca_all_std, y_all)\n",
    "dl_all_ca = DataLoader(ds_all_ca, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "fused_all_list = []\n",
    "with torch.no_grad():\n",
    "    for X1_b, X2_b, y_b in dl_all_ca:\n",
    "        X1_b = X1_b.to(device)\n",
    "        X2_b = X2_b.to(device)\n",
    "        fused = encoder_tp(X1_b, X2_b)\n",
    "        fused_all_list.append(fused.cpu().numpy())\n",
    "\n",
    "fused_all_TP = np.concatenate(fused_all_list, axis=0)  # (N, hidden_dim)\n",
    "print(\"fused_all_TP 形状:\", fused_all_TP.shape)\n",
    "\n",
    "# 7) 保存 Cross-Attn 模型 & fusion embeddings\n",
    "torch.save(\n",
    "    {\n",
    "        \"state_dict\": best_state_dict,\n",
    "        \"config\": {\n",
    "            \"dim_a\": dim_a,\n",
    "            \"dim_b\": dim_b,\n",
    "            \"hidden_dim\": 256,\n",
    "            \"num_heads\": 4,\n",
    "            \"mlp_hidden\": 512,\n",
    "            \"dropout\": 0.1,\n",
    "        },\n",
    "    },\n",
    "    MODELS_CA / \"crossattn_T_P_best.pt\"\n",
    ")\n",
    "\n",
    "np.save(OUT_TP / \"fused_all_T_P.npy\", fused_all_TP)\n",
    "np.save(OUT_TP / \"row_id_all_T_P.npy\", rowid_all)\n",
    "np.save(OUT_TP / \"y_all_T_P.npy\",      y_all)\n",
    "np.save(OUT_TP / \"groups_all_T_P.npy\", groups_all)\n",
    "\n",
    "with open(OUT_TP / \"crossattn_T_P_history.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_epoch\": best_epoch,\n",
    "            \"best_val_mae\": float(best_val_mae),\n",
    "            \"history\": history_ca,\n",
    "            \"n_all\": int(len(y_all)),\n",
    "            \"n_train\": int(len(ca_train_idx)),\n",
    "            \"n_val\": int(len(ca_val_idx)),\n",
    "        },\n",
    "        f,\n",
    "        ensure_ascii=False,\n",
    "        indent=2,\n",
    "        default=np_encoder,\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ Cross-Attn (Text+Phys) 训练完成，fused_all_T_P 已保存。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06679b7c-5256-4cc6-bc87-c7591027561f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c820f02-3315-4346-a25f-519ad09f2766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF T+P train 样本数: 2726\n",
      "RF T+P test  样本数: 680\n",
      "dur_all_std_rf 形状: (3406, 1)\n",
      "X_all_RF 形状: (3406, 260)\n",
      "X_train_RF 形状: (2726, 260)\n",
      "X_test_RF  形状: (680, 260)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 7: RF 端 8:2 划分 & 构造 RF 输入特征 =====\n",
    "\n",
    "gss_rf = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=3031)\n",
    "N = len(y_all)\n",
    "\n",
    "rf_train_idx, rf_test_idx = next(\n",
    "    gss_rf.split(np.zeros(N), y_all, groups_all)\n",
    ")\n",
    "rf_train_idx = np.array(rf_train_idx, dtype=np.int64)\n",
    "rf_test_idx  = np.array(rf_test_idx, dtype=np.int64)\n",
    "\n",
    "print(\"RF T+P train 样本数:\", len(rf_train_idx))\n",
    "print(\"RF T+P test  样本数:\", len(rf_test_idx))\n",
    "\n",
    "np.save(OUT_TP / \"rf_train_idx_T_P.npy\", rf_train_idx)\n",
    "np.save(OUT_TP / \"rf_test_idx_T_P.npy\",  rf_test_idx)\n",
    "\n",
    "# RF 专用的 duration scaler（只在 RF train80% 上 fit）\n",
    "scaler_dur_rf = StandardScaler().fit(dur_raw[rf_train_idx])\n",
    "dur_all_std_rf = scaler_dur_rf.transform(dur_raw)\n",
    "print(\"dur_all_std_rf 形状:\", dur_all_std_rf.shape)\n",
    "\n",
    "# RF 输入特征：fusion embedding + duration_std + one-hot\n",
    "X_all_RF = np.concatenate(\n",
    "    [fused_all_TP, dur_all_std_rf, cat_all],\n",
    "    axis=1\n",
    ")\n",
    "print(\"X_all_RF 形状:\", X_all_RF.shape)\n",
    "\n",
    "X_train_RF = X_all_RF[rf_train_idx]\n",
    "y_train_RF = y_all[rf_train_idx]\n",
    "groups_train_RF = groups_all[rf_train_idx]\n",
    "\n",
    "X_test_RF  = X_all_RF[rf_test_idx]\n",
    "y_test_RF  = y_all[rf_test_idx]\n",
    "\n",
    "print(\"X_train_RF 形状:\", X_train_RF.shape)\n",
    "print(\"X_test_RF  形状:\", X_test_RF.shape)\n",
    "\n",
    "np.save(OUT_TP / \"X_all_RF_T_P.npy\", X_all_RF)\n",
    "np.save(OUT_TP / \"X_train_RF_T_P.npy\", X_train_RF)\n",
    "np.save(OUT_TP / \"X_test_RF_T_P.npy\",  X_test_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0a40d-e237-4227-b128-a7c4e2829d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5053c75e-4abb-4676-b97f-4ccf119ea193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始在 RF 80% train 上做十折 GroupKFold 随机超参搜索（T+P fused + meta）...\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "\n",
      "[T+P+meta→RF] 最优超参：\n",
      "{'n_estimators': 800, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 0.8, 'max_depth': 40}\n",
      "最优 CV 分数 (neg MAE): -0.42783054017874633\n",
      "\n",
      "===== [T+P fused + meta → RF] RF train80% 指标 =====\n",
      "MAE: 0.1879\n",
      "RMSE: 0.2923\n",
      "R2: 0.9408\n",
      "Pearson_r: 0.9714\n",
      "\n",
      "===== [T+P fused + meta → RF] RF test20% 指标 =====\n",
      "MAE: 0.4099\n",
      "RMSE: 0.5885\n",
      "R2: 0.7439\n",
      "Pearson_r: 0.8626\n",
      "\n",
      "✅ RF (T+P fused + meta) 训练 & 评估完成。\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 8: RF 十折 CV + RandomizedSearchCV (T+P) =====\n",
    "\n",
    "param_distributions_rf = {\n",
    "    \"n_estimators\":      [200, 300, 500, 800, 1000],\n",
    "    \"max_depth\":         [None, 10, 20, 30, 40],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\":  [1, 2, 4],\n",
    "    \"max_features\":      [\"sqrt\", \"log2\", 0.3, 0.5, 0.8],\n",
    "}\n",
    "\n",
    "rf_base = RandomForestRegressor(\n",
    "    random_state=GLOBAL_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "cv_inner = GroupKFold(n_splits=10)\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=param_distributions_rf,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=cv_inner,\n",
    "    n_jobs=-1,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"开始在 RF 80% train 上做十折 GroupKFold 随机超参搜索（T+P fused + meta）...\")\n",
    "rf_search.fit(X_train_RF, y_train_RF, groups=groups_train_RF)\n",
    "\n",
    "best_params_rf = rf_search.best_params_\n",
    "best_score_rf  = rf_search.best_score_\n",
    "\n",
    "print(\"\\n[T+P+meta→RF] 最优超参：\")\n",
    "print(best_params_rf)\n",
    "print(\"最优 CV 分数 (neg MAE):\", best_score_rf)\n",
    "\n",
    "# 用最优超参在 RF train80% 上重训\n",
    "rf_final = RandomForestRegressor(\n",
    "    **best_params_rf,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf_final.fit(X_train_RF, y_train_RF)\n",
    "\n",
    "# 评估 train80% & test20%\n",
    "y_train_pred_RF = rf_final.predict(X_train_RF)\n",
    "y_test_pred_RF  = rf_final.predict(X_test_RF)\n",
    "\n",
    "metrics_train_RF = compute_regression_metrics(y_train_RF, y_train_pred_RF)\n",
    "metrics_test_RF  = compute_regression_metrics(y_test_RF,  y_test_pred_RF)\n",
    "\n",
    "print(\"\\n===== [T+P fused + meta → RF] RF train80% 指标 =====\")\n",
    "for k, v in metrics_train_RF.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n===== [T+P fused + meta → RF] RF test20% 指标 =====\")\n",
    "for k, v in metrics_test_RF.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# 保存 RF 模型 & 结果\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"model\": rf_final,\n",
    "        \"scaler_text_ca\": scaler_text_ca,\n",
    "        \"scaler_phys_ca\": scaler_phys_ca,\n",
    "        \"encoder_state_dict\": best_state_dict,\n",
    "        \"scaler_dur_rf\": scaler_dur_rf,\n",
    "        \"cat_feature_names\": cat_feature_names,\n",
    "        \"config\": {\n",
    "            \"hidden_dim\": 256,\n",
    "            \"GLOBAL_SEED\": int(GLOBAL_SEED),\n",
    "            \"param_distributions_rf\": param_distributions_rf,\n",
    "        },\n",
    "    },\n",
    "    MODELS_RF / \"rf_T_P_meta_from_CA.joblib\"\n",
    ")\n",
    "\n",
    "np.save(OUT_TP / \"y_train_RF_T_P.npy\", y_train_RF)\n",
    "np.save(OUT_TP / \"y_test_RF_T_P.npy\",  y_test_RF)\n",
    "np.save(OUT_TP / \"y_train_pred_RF_T_P.npy\", y_train_pred_RF)\n",
    "np.save(OUT_TP / \"y_test_pred_RF_T_P.npy\",  y_test_pred_RF)\n",
    "\n",
    "with open(OUT_TP / \"metrics_RF_T_P_meta_from_CA.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_rf\": best_params_rf,\n",
    "            \"best_score_cv_neg_mae\": float(best_score_rf),\n",
    "            \"train80_metrics\": metrics_train_RF,\n",
    "            \"test20_metrics\": metrics_test_RF,\n",
    "            \"n_all\": int(len(y_all)),\n",
    "            \"n_train80_rf\": int(len(y_train_RF)),\n",
    "            \"n_test20_rf\": int(len(y_test_RF)),\n",
    "        },\n",
    "        f,\n",
    "        ensure_ascii=False,\n",
    "        indent=2,\n",
    "        default=np_encoder,\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ RF (T+P fused + meta) 训练 & 评估完成。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
