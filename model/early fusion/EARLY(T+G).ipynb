{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91fadd9e-3803-4120-b219-bf37ec1b6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: 依赖导入 & 工具函数 =====\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "\n",
    "def compute_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"计算回归指标：MAE, RMSE, R2, Pearson_r\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "\n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        pr = float(\"nan\")\n",
    "    else:\n",
    "        pr, _ = pearsonr(y_true, y_pred)\n",
    "        pr = float(pr)\n",
    "\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"Pearson_r\": pr}\n",
    "\n",
    "def np_encoder(o):\n",
    "    if isinstance(o, (np.integer,)):\n",
    "        return int(o)\n",
    "    if isinstance(o, (np.floating,)):\n",
    "        return float(o)\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    raise TypeError(f\"Type {type(o)} not serializable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15a5af4-85ea-4f03-98ab-6abf00b11802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT_EMB_768 : /root/Invertebrates_EC50_multi_fusion/SMILES/smiles_outputs/reg_smiles_cls_embeddings_all.npy\n",
      "GRAPH_EMB_PATH: /root/Invertebrates_EC50_multi_fusion/graph/graph_outputs/reg_graph_embeddings.npy\n",
      "DATA_PATH    : /root/fusion_dataset/Invertebrates_EC50_unique.xlsx\n",
      "OUT_DIR_TG   : /root/Invertebrates_EC50_multi_fusion/early(T+G)/text_plus_graph_simple\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: 路径 & RF 超参空间 =====\n",
    "\n",
    "ROOT_MULTI = Path(\"/root/Invertebrates_EC50_multi_fusion\")\n",
    "\n",
    "# 文本 CLS 全量嵌入（与 df 行号对齐）\n",
    "TEXT_DIR      = ROOT_MULTI / \"SMILES\" / \"smiles_outputs\"\n",
    "TEXT_EMB_768  = TEXT_DIR / \"reg_smiles_cls_embeddings_all.npy\"\n",
    "\n",
    "# 图端 embedding + row_id\n",
    "GRAPH_DIR        = ROOT_MULTI / \"graph\" / \"graph_outputs\"\n",
    "GRAPH_EMB_PATH   = GRAPH_DIR / \"reg_graph_embeddings.npy\"\n",
    "GRAPH_ROWID_PATH = GRAPH_DIR / \"row_id_graph_for_emb.npy\"\n",
    "\n",
    "# 原始数据表（含 SMILES / mgperL / Duration / Effect / Endpoint）\n",
    "DATA_PATH = Path(\"/root/fusion_dataset/Invertebrates_EC50_unique.xlsx\")\n",
    "\n",
    "# 输出目录：Text + Graph 早期融合（简化版）\n",
    "FUSION_ROOT_TG = ROOT_MULTI / \"early(T+G)\"\n",
    "OUT_DIR_TG     = FUSION_ROOT_TG / \"text_plus_graph_simple\"\n",
    "MODELS_DIR_TG  = OUT_DIR_TG / \"models\"\n",
    "for d in [FUSION_ROOT_TG, OUT_DIR_TG, MODELS_DIR_TG]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 列名（按你的表改）\n",
    "SMILES_COL   = \"SMILES_Canonical_RDKit\"\n",
    "EFFECT_COL   = \"Effect\"\n",
    "ENDPOINT_COL = \"Endpoint\"\n",
    "DURATION_COL = \"Duration_Value(hour)\"   # 如果不一样就改\n",
    "LABEL_RAW    = \"mgperL\"\n",
    "LABEL_LOG    = \"mgperL_log\"\n",
    "LABEL_COL    = LABEL_LOG                # 想用原始 mg/L 就改成 LABEL_RAW\n",
    "\n",
    "# 文本降维目标：768 -> 256\n",
    "TEXT_DIM_TARGET = 256\n",
    "\n",
    "# RF 随机搜索空间\n",
    "param_distributions_rf = {\n",
    "    \"n_estimators\":      [200, 300, 500, 800, 1000],\n",
    "    \"max_depth\":         [None, 10, 20, 30, 40],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\":  [1, 2, 4],\n",
    "    \"max_features\":      [\"sqrt\", \"log2\", 0.3, 0.5, 0.8],\n",
    "}\n",
    "\n",
    "print(\"TEXT_EMB_768 :\", TEXT_EMB_768)\n",
    "print(\"GRAPH_EMB_PATH:\", GRAPH_EMB_PATH)\n",
    "print(\"DATA_PATH    :\", DATA_PATH)\n",
    "print(\"OUT_DIR_TG   :\", OUT_DIR_TG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e249c7-6f7c-46c9-b6bd-bd21bfb7ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede8c20b-f94e-40fb-83b0-5a30f661f6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df 形状: (3620, 12)\n",
      "   row_id    SMILES_Canonical_RDKit  mgperL  mgperL_log  Duration_Value(hour)  \\\n",
      "0       0        [Cl-].[Cl-].[Zn+2]     1.3    0.113943                  96.0   \n",
      "1       1  O=S(=O)([O-])[O-].[Zn+2]     2.5    0.397940                  24.0   \n",
      "2       2        [Cl-].[Cl-].[Pb+2]    40.8    1.610660                  96.0   \n",
      "3       3  O=S(=O)([O-])[O-].[Cu+2]     1.9    0.278754                  24.0   \n",
      "4       4  O=S(=O)([O-])[O-].[Cu+2]     0.6   -0.221849                  96.0   \n",
      "\n",
      "  Effect Endpoint  \n",
      "0    ITX     EC50  \n",
      "1    ITX     EC50  \n",
      "2    ITX     EC50  \n",
      "3    ITX     EC50  \n",
      "4    ITX     EC50  \n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 3: 读取 df & 构造 mgperL_log =====\n",
    "\n",
    "df = pd.read_excel(DATA_PATH, engine=\"openpyxl\")\n",
    "\n",
    "# 保证有 row_id，与 embedding 一致\n",
    "if \"row_id\" not in df.columns:\n",
    "    df = df.reset_index().rename(columns={\"index\": \"row_id\"})\n",
    "df[\"row_id\"] = df[\"row_id\"].astype(int)\n",
    "\n",
    "# 标签：若没有 mgperL_log，则由 mgperL 生成\n",
    "if LABEL_LOG not in df.columns:\n",
    "    df[LABEL_RAW] = pd.to_numeric(df[LABEL_RAW], errors=\"coerce\")\n",
    "    mask_valid = df[LABEL_RAW] > 0\n",
    "    df[LABEL_LOG] = np.where(mask_valid, np.log10(df[LABEL_RAW]), np.nan)\n",
    "\n",
    "print(\"df 形状:\", df.shape)\n",
    "print(df[[\"row_id\", SMILES_COL, LABEL_RAW, LABEL_LOG, DURATION_COL, EFFECT_COL, ENDPOINT_COL]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e76c9-f2eb-4647-af27-ab73a92e312a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5878db5f-9e9d-4793-89e7-9e028ba1a76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_all 形状: (3620, 768)\n",
      "graph_emb 形状: (3213, 256)\n",
      "rowid_graph 范围: 1 → 3619\n",
      "Text+Graph row_id 交集样本数: 3213\n",
      "对齐后样本数: 3213\n",
      "text_tg  形状: (3213, 768)\n",
      "graph_tg 形状: (3213, 256)\n",
      "y_tg     形状: (3213,)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 4: 加载 Text & Graph embedding，对齐 row_id =====\n",
    "\n",
    "# 1) 文本 CLS 全量嵌入（按 df 行号顺序）\n",
    "text_all = np.load(TEXT_EMB_768)\n",
    "assert text_all.shape[0] == len(df), \"text_all 行数与 df 不一致，请检查。\"\n",
    "print(\"text_all 形状:\", text_all.shape)\n",
    "\n",
    "# 2) 图端 embedding + row_id\n",
    "graph_emb   = np.load(GRAPH_EMB_PATH)                # (N_graph, d_g)\n",
    "rowid_graph = np.load(GRAPH_ROWID_PATH).astype(int)  # (N_graph,)\n",
    "print(\"graph_emb 形状:\", graph_emb.shape)\n",
    "print(\"rowid_graph 范围:\", rowid_graph.min(), \"→\", rowid_graph.max())\n",
    "\n",
    "# 3) 按 row_id 交集对齐 Text+Graph 子集\n",
    "df_indexed = df.set_index(\"row_id\")\n",
    "\n",
    "ids_graph = set(rowid_graph.tolist())\n",
    "ids_all   = set(df_indexed.index.tolist())\n",
    "ids_intersection = sorted(list(ids_graph & ids_all))\n",
    "\n",
    "print(\"Text+Graph row_id 交集样本数:\", len(ids_intersection))\n",
    "\n",
    "# 建映射：row_id -> graph_emb 下标\n",
    "idx_map_graph = {rid: i for i, rid in enumerate(rowid_graph)}\n",
    "\n",
    "meta_tg_list  = []\n",
    "text_tg_list  = []\n",
    "graph_tg_list = []\n",
    "y_tg_list     = []\n",
    "rowid_tg_list = []\n",
    "\n",
    "for rid in ids_intersection:\n",
    "    row_meta = df_indexed.loc[rid]\n",
    "    label = row_meta[LABEL_COL]\n",
    "    if pd.isna(label) or not np.isfinite(label):\n",
    "        continue\n",
    "\n",
    "    meta_tg_list.append(row_meta)\n",
    "    text_tg_list.append(text_all[rid])              # 文本 CLS\n",
    "    graph_tg_list.append(graph_emb[idx_map_graph[rid]])  # 图 embedding\n",
    "    y_tg_list.append(label)\n",
    "    rowid_tg_list.append(rid)\n",
    "\n",
    "meta_tg  = pd.DataFrame(meta_tg_list).reset_index(drop=True)\n",
    "text_tg  = np.stack(text_tg_list, axis=0)\n",
    "graph_tg = np.stack(graph_tg_list, axis=0)\n",
    "y_tg     = np.array(y_tg_list, dtype=float)\n",
    "rowid_tg = np.array(rowid_tg_list, dtype=int)\n",
    "\n",
    "print(\"对齐后样本数:\", len(y_tg))\n",
    "print(\"text_tg  形状:\", text_tg.shape)\n",
    "print(\"graph_tg 形状:\", graph_tg.shape)\n",
    "print(\"y_tg     形状:\", y_tg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939c7b2-a49c-435b-ab9c-e4094074d3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f2f0da-939b-43cc-bb22-9327a4c00056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始样本数: 3213\n",
      "保留样本数: 3213\n",
      "过滤后 text_tg  形状: (3213, 768)\n",
      "过滤后 graph_tg 形状: (3213, 256)\n",
      "过滤后 y_tg    形状: (3213,)\n",
      "cat_tg 形状: (3213, 3)\n",
      "dur_tg 形状: (3213, 1)\n",
      "样本总数 N_tg: 3213\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 5: 构造 Duration + Effect/Endpoint One-Hot + SMILES 分组 =====\n",
    "\n",
    "meta2 = meta_tg.copy()\n",
    "\n",
    "# 过滤：Duration / Effect / Endpoint 必须存在\n",
    "mask_keep_tg = (\n",
    "    meta2[DURATION_COL].notna()\n",
    "    & meta2[EFFECT_COL].notna()\n",
    "    & meta2[ENDPOINT_COL].notna()\n",
    ")\n",
    "\n",
    "print(\"初始样本数:\", len(meta2))\n",
    "print(\"保留样本数:\", int(mask_keep_tg.sum()))\n",
    "\n",
    "meta2    = meta2.loc[mask_keep_tg].reset_index(drop=True)\n",
    "text_tg  = text_tg[mask_keep_tg.values]\n",
    "graph_tg = graph_tg[mask_keep_tg.values]\n",
    "y_tg     = y_tg[mask_keep_tg.values]\n",
    "rowid_tg = rowid_tg[mask_keep_tg.values]\n",
    "\n",
    "print(\"过滤后 text_tg  形状:\", text_tg.shape)\n",
    "print(\"过滤后 graph_tg 形状:\", graph_tg.shape)\n",
    "print(\"过滤后 y_tg    形状:\", y_tg.shape)\n",
    "\n",
    "# One-hot：Effect + Endpoint\n",
    "cat_cols = [EFFECT_COL, ENDPOINT_COL]\n",
    "cat_dummies_tg = pd.get_dummies(meta2[cat_cols], dummy_na=False)\n",
    "cat_tg = cat_dummies_tg.values.astype(float)\n",
    "cat_feature_names_tg = list(cat_dummies_tg.columns)\n",
    "\n",
    "# Duration 数值特征\n",
    "meta2[DURATION_COL] = pd.to_numeric(meta2[DURATION_COL], errors=\"coerce\")\n",
    "dur_median_tg = meta2[DURATION_COL].median()\n",
    "meta2[DURATION_COL] = meta2[DURATION_COL].fillna(dur_median_tg)\n",
    "dur_tg = meta2[[DURATION_COL]].values.astype(float)\n",
    "numeric_feature_names_tg = [DURATION_COL]\n",
    "\n",
    "# 分组 SMILES\n",
    "groups_tg = meta2[SMILES_COL].astype(str).values\n",
    "\n",
    "print(\"cat_tg 形状:\", cat_tg.shape)\n",
    "print(\"dur_tg 形状:\", dur_tg.shape)\n",
    "print(\"样本总数 N_tg:\", len(y_tg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cd538-122b-4fdc-ba77-eafa5444b51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2186e70-0315-44d2-a891-dbf4b183d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+Graph train 样本数: 2581\n",
      "Text+Graph test  样本数: 632\n",
      "text_train_256 形状: (2581, 256)\n",
      "X_train_tg 形状: (2581, 516)\n",
      "X_test_tg  形状: (632, 516)\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 6: 8:2 按 SMILES 分组划分 + 构造最终特征 =====\n",
    "\n",
    "N_tg = len(y_tg)\n",
    "gss_tg = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=2025)\n",
    "\n",
    "train_idx_tg, test_idx_tg = next(\n",
    "    gss_tg.split(np.zeros(N_tg), y_tg, groups=groups_tg)\n",
    ")\n",
    "\n",
    "train_idx_tg = np.array(train_idx_tg, dtype=np.int64)\n",
    "test_idx_tg  = np.array(test_idx_tg, dtype=np.int64)\n",
    "\n",
    "print(\"Text+Graph train 样本数:\", len(train_idx_tg))\n",
    "print(\"Text+Graph test  样本数:\", len(test_idx_tg))\n",
    "\n",
    "# 保存索引和 row_id，方便后续分析\n",
    "np.save(OUT_DIR_TG / \"train_idx_tg.npy\", train_idx_tg)\n",
    "np.save(OUT_DIR_TG / \"test_idx_tg.npy\",  test_idx_tg)\n",
    "np.save(OUT_DIR_TG / \"row_id_train_tg.npy\", rowid_tg[train_idx_tg])\n",
    "np.save(OUT_DIR_TG / \"row_id_test_tg.npy\",  rowid_tg[test_idx_tg])\n",
    "\n",
    "# ========== 构造 train/test 各模态原始特征 ==========\n",
    "text_train_raw  = text_tg[train_idx_tg]\n",
    "text_test_raw   = text_tg[test_idx_tg]\n",
    "\n",
    "graph_train_raw = graph_tg[train_idx_tg]\n",
    "graph_test_raw  = graph_tg[test_idx_tg]\n",
    "\n",
    "dur_train_raw   = dur_tg[train_idx_tg]\n",
    "dur_test_raw    = dur_tg[test_idx_tg]\n",
    "\n",
    "cat_train       = cat_tg[train_idx_tg]\n",
    "cat_test        = cat_tg[test_idx_tg]\n",
    "\n",
    "y_train_tg      = y_tg[train_idx_tg]\n",
    "y_test_tg       = y_tg[test_idx_tg]\n",
    "groups_train_tg = groups_tg[train_idx_tg]\n",
    "\n",
    "# ========== 只在 train80% 上拟合 scaler & SVD ==========\n",
    "# 1) 标准化\n",
    "scaler_text  = StandardScaler().fit(text_train_raw)\n",
    "scaler_graph = StandardScaler().fit(graph_train_raw)\n",
    "scaler_dur   = StandardScaler().fit(dur_train_raw)\n",
    "\n",
    "text_train_std  = scaler_text.transform(text_train_raw)\n",
    "text_test_std   = scaler_text.transform(text_test_raw)\n",
    "\n",
    "graph_train_std = scaler_graph.transform(graph_train_raw)\n",
    "graph_test_std  = scaler_graph.transform(graph_test_raw)\n",
    "\n",
    "dur_train_std   = scaler_dur.transform(dur_train_raw)\n",
    "dur_test_std    = scaler_dur.transform(dur_test_raw)\n",
    "\n",
    "# 2) 文本降维：768 -> 256（只在 train80% 上 fit，一起 transform test）\n",
    "svd_text = TruncatedSVD(\n",
    "    n_components=TEXT_DIM_TARGET,\n",
    "    random_state=GLOBAL_SEED\n",
    ")\n",
    "text_train_256 = svd_text.fit_transform(text_train_std)\n",
    "text_test_256  = svd_text.transform(text_test_std)\n",
    "\n",
    "print(\"text_train_256 形状:\", text_train_256.shape)\n",
    "\n",
    "# 3) 拼接最终特征：[text_256, graph_std, dur_std, onehot]\n",
    "X_train_tg = np.concatenate(\n",
    "    [text_train_256, graph_train_std, dur_train_std, cat_train], axis=1\n",
    ")\n",
    "X_test_tg = np.concatenate(\n",
    "    [text_test_256, graph_test_std, dur_test_std, cat_test], axis=1\n",
    ")\n",
    "\n",
    "print(\"X_train_tg 形状:\", X_train_tg.shape)\n",
    "print(\"X_test_tg  形状:\", X_test_tg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d08b3f0b-c5ed-45c8-975f-01d3fb949a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all_tg 形状: (3213, 516)\n",
      "✅ Text+Graph 早期融合 embeddings 已保存到: /root/Invertebrates_EC50_multi_fusion/early(T+G)/text_plus_graph_simple\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 7: 保存 Text+Graph 早期融合后的 embeddings =====\n",
    "\n",
    "# 1) 用在 train80% 上拟合好的 scaler/SVD，对“所有样本”做一次 transform\n",
    "text_all_std  = scaler_text.transform(text_tg)    # (N_all, 768) -> 标准化\n",
    "graph_all_std = scaler_graph.transform(graph_tg)  # (N_all, d_g) -> 标准化\n",
    "dur_all_std   = scaler_dur.transform(dur_tg)      # (N_all, 1)   -> 标准化\n",
    "\n",
    "# 文本 768 -> 256，用的是刚才在 train80% 拟合好的 svd_text\n",
    "text_all_256 = svd_text.transform(text_all_std)   # (N_all, 256)\n",
    "\n",
    "# 2) 在“全体样本”上拼接早期融合特征：[text_256, graph_std, dur_std, onehot]\n",
    "X_all_tg = np.concatenate(\n",
    "    [text_all_256, graph_all_std, dur_all_std, cat_tg],\n",
    "    axis=1\n",
    ")\n",
    "print(\"X_all_tg 形状:\", X_all_tg.shape)\n",
    "\n",
    "# 3) 把 train/test 的特征和“全体 fused embedding”都存下来\n",
    "np.save(OUT_DIR_TG / \"X_train_tg.npy\", X_train_tg)\n",
    "np.save(OUT_DIR_TG / \"X_test_tg.npy\",  X_test_tg)\n",
    "np.save(OUT_DIR_TG / \"y_train_tg.npy\", y_train_tg)\n",
    "np.save(OUT_DIR_TG / \"y_test_tg.npy\",  y_test_tg)\n",
    "\n",
    "# 全部样本的 fused embedding + row_id，用于之后中期/晚期融合对齐\n",
    "np.save(OUT_DIR_TG / \"X_all_tg_fused.npy\", X_all_tg)\n",
    "np.save(OUT_DIR_TG / \"row_id_all_tg.npy\",  rowid_tg)\n",
    "\n",
    "print(\"✅ Text+Graph 早期融合 embeddings 已保存到:\", OUT_DIR_TG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7d7e9-b8b4-4514-b61f-20c311b25ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088ccd5a-8ae4-48aa-a27c-9364aa0407c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始在 Text+Graph train80% 上用十折 GroupKFold 调参 RF ...\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=66.3min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.1min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=12.1min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=22.3min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=49.1min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=19.0min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.8min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=43.1min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.6min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.6min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=15.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 8.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.3min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=66.7min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.9min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=12.1min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=10.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=25.9min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=49.7min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=29.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=15.4min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=17.0min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=16.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 8.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.2min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=87.7min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=26.3min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  46.0s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  51.3s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  46.8s\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.7min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.5min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.3min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 3.0min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  57.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.7min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  47.4s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=20.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.9min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=41.7min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 9.0min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.5min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=29.8min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=66.4min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.1min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=11.8min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=21.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=51.4min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=30.9min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=39.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.6min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=16.6min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.5min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=67.4min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.6min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=11.8min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=11.5min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=25.8min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=48.4min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=30.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=16.3min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.6min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=16.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 8.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.3min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=64.6min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=57.7min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  51.9s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  47.0s\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.3min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.4min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 3.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.7min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.4min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  59.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  45.2s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  51.8s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=20.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=43.1min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.6min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.5min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=29.8min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.6min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=65.5min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.0min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.0min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=11.8min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=21.4min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=50.1min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=31.6min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=16.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=14.1min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=17.4min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=30.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.9min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=84.1min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=22.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=49.7min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=18.6min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=43.2min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 8.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.5min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.9min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=28.7min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.4min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=63.5min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=59.8min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  43.7s\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.0min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=14.0min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  43.7s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=19.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=43.0min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.1min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=29.7min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.6min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.0min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=82.7min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=10.8min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=25.9min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  49.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  42.8s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  47.7s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  51.3s\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=12.7min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=19.0min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=28.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=15.8min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.5min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=15.9min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 8.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=16.1min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=83.7min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=22.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=26.4min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.3min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.8min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.9min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  37.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.8s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=20.0min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=43.2min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=15.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=14.8min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=84.0min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=11.1min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=25.5min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=51.2min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=29.6min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=15.0min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 8.4min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=17.0min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=30.3min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=16.0min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=85.5min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=22.0min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=26.3min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.2min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 3.0min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  43.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  50.4s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=19.6min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=29.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=14.7min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 8.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.8min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=16.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.8min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.5min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=64.7min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.8min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=11.8min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=21.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.6min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=50.2min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=31.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=16.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=14.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.9min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=28.8min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.6min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.3min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=85.2min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=21.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=27.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=14.0min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.6min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  44.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  48.5s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=20.2min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.9min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=41.1min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.6min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=28.1min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.6min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.6min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=85.2min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=21.8min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=27.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=13.7min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.8min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=19.8min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=40.9min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 9.2min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.6min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=29.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.8min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=85.9min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.7min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=25.2min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=49.2min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=29.9min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=16.0min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 8.2min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.6min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=29.2min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.6min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.8min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=85.7min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=21.1min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=50.7min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=30.7min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=39.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 2.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=15.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=15.4min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.7min\n",
      "\n",
      "Text+Graph 最优超参 (基于 train80% 十折 CV):\n",
      "{'n_estimators': 800, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 0.8, 'max_depth': 40}\n",
      "最优CV分数 (neg MAE): -0.5379739440632464\n",
      "\n",
      "===== Text+Graph 最终 RF：train(80%) 指标 =====\n",
      "MAE: 0.1872\n",
      "RMSE: 0.2729\n",
      "R2: 0.9438\n",
      "Pearson_r: 0.9758\n",
      "\n",
      "===== Text+Graph 最终 RF：独立 test(20%) 指标 =====\n",
      "MAE: 0.5172\n",
      "RMSE: 0.7002\n",
      "R2: 0.6655\n",
      "Pearson_r: 0.8221\n",
      "\n",
      "✅ Text+Graph 最终模型 & 指标已保存：\n",
      "   模型路径: /root/Invertebrates_EC50_multi_fusion/early(T+G)/text_plus_graph_simple/rf_text_graph_8_2_final_simple.joblib\n",
      "   指标路径: /root/Invertebrates_EC50_multi_fusion/early(T+G)/text_plus_graph_simple/metrics_text_graph_rf_8_2_simple.json\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 7: 十折 GroupKFold 调参 + 最终模型 & test 评估 =====\n",
    "\n",
    "# 1) 定义 RF 基模型\n",
    "rf_base_tg = RandomForestRegressor(\n",
    "    random_state=GLOBAL_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 2) 十折 GroupKFold（只在 train80% 内，按 SMILES 分组）\n",
    "cv_tg = GroupKFold(n_splits=10)\n",
    "\n",
    "# 3) RandomizedSearchCV：以 neg MAE 为优化目标\n",
    "rf_search_tg = RandomizedSearchCV(\n",
    "    estimator=rf_base_tg,\n",
    "    param_distributions=param_distributions_rf,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=cv_tg,\n",
    "    n_jobs=-1,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"开始在 Text+Graph train80% 上用十折 GroupKFold 调参 RF ...\")\n",
    "rf_search_tg.fit(X_train_tg, y_train_tg, groups=groups_train_tg)\n",
    "\n",
    "best_params_tg = rf_search_tg.best_params_\n",
    "best_score_tg  = rf_search_tg.best_score_\n",
    "\n",
    "print(\"\\nText+Graph 最优超参 (基于 train80% 十折 CV):\")\n",
    "print(best_params_tg)\n",
    "print(\"最优CV分数 (neg MAE):\", best_score_tg)\n",
    "\n",
    "# 4) 用最优超参在整个 train80% 上重训最终模型\n",
    "rf_final_tg = RandomForestRegressor(\n",
    "    **best_params_tg,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf_final_tg.fit(X_train_tg, y_train_tg)\n",
    "\n",
    "# 5) 在 train80% & test20% 上评估\n",
    "y_train_pred_tg = rf_final_tg.predict(X_train_tg)\n",
    "y_test_pred_tg  = rf_final_tg.predict(X_test_tg)\n",
    "\n",
    "metrics_train_tg = compute_regression_metrics(y_train_tg, y_train_pred_tg)\n",
    "metrics_test_tg  = compute_regression_metrics(y_test_tg,  y_test_pred_tg)\n",
    "\n",
    "print(\"\\n===== Text+Graph 最终 RF：train(80%) 指标 =====\")\n",
    "for k, v in metrics_train_tg.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n===== Text+Graph 最终 RF：独立 test(20%) 指标 =====\")\n",
    "for k, v in metrics_test_tg.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# 6) 保存模型、变换器、预测和指标\n",
    "FINAL_MODEL_TG_PATH  = OUT_DIR_TG / \"rf_text_graph_8_2_final_simple.joblib\"\n",
    "METRICS_TG_JSON_PATH = OUT_DIR_TG / \"metrics_text_graph_rf_8_2_simple.json\"\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"model\": rf_final_tg,\n",
    "        \"scaler_text\": scaler_text,\n",
    "        \"svd_text\": svd_text,\n",
    "        \"scaler_graph\": scaler_graph,\n",
    "        \"scaler_dur\": scaler_dur,\n",
    "        \"cat_feature_names\": cat_feature_names_tg,\n",
    "        \"numeric_feature_names\": numeric_feature_names_tg,\n",
    "        \"config\": {\n",
    "            \"TEXT_DIM_TARGET\": TEXT_DIM_TARGET,\n",
    "            \"GLOBAL_SEED\": int(GLOBAL_SEED),\n",
    "            \"param_distributions\": param_distributions_rf,\n",
    "        },\n",
    "    },\n",
    "    FINAL_MODEL_TG_PATH\n",
    ")\n",
    "\n",
    "np.save(OUT_DIR_TG / \"y_train_tg.npy\",      y_train_tg)\n",
    "np.save(OUT_DIR_TG / \"y_train_pred_tg.npy\", y_train_pred_tg)\n",
    "np.save(OUT_DIR_TG / \"y_test_tg.npy\",       y_test_tg)\n",
    "np.save(OUT_DIR_TG / \"y_test_pred_tg.npy\",  y_test_pred_tg)\n",
    "\n",
    "with open(METRICS_TG_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_cv\": best_params_tg,\n",
    "            \"best_score_cv_neg_mae\": float(best_score_tg),\n",
    "            \"train_metrics\": metrics_train_tg,\n",
    "            \"test_metrics\": metrics_test_tg,\n",
    "            \"n_total\": int(len(y_tg)),\n",
    "            \"n_train\": int(len(y_train_tg)),\n",
    "            \"n_test\": int(len(y_test_tg)),\n",
    "        },\n",
    "        f,\n",
    "        ensure_ascii=False,\n",
    "        indent=2,\n",
    "        default=np_encoder,\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ Text+Graph 最终模型 & 指标已保存：\")\n",
    "print(\"   模型路径:\", FINAL_MODEL_TG_PATH)\n",
    "print(\"   指标路径:\", METRICS_TG_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8139a8-6c27-46c9-914c-914b9c837da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eaa05c-06f7-4703-8927-34413fc3b6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38928e55-8cb5-4fe7-91fb-eaa42c7d9c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
