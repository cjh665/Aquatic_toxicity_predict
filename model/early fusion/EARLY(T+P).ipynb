{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91fadd9e-3803-4120-b219-bf37ec1b6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Notebook 1 – Cell 1: 依赖 & 工具函数 =====\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "GLOBAL_SEED = 42\n",
    "\n",
    "def compute_regression_metrics(y_true, y_pred):\n",
    "    \"\"\"计算回归指标：MAE, RMSE, R2, Pearson_r\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "\n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        pr = float(\"nan\")\n",
    "    else:\n",
    "        pr, _ = pearsonr(y_true, y_pred)\n",
    "        pr = float(pr)\n",
    "\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2, \"Pearson_r\": pr}\n",
    "\n",
    "def np_encoder(o):\n",
    "    if isinstance(o, (np.integer,)):\n",
    "        return int(o)\n",
    "    if isinstance(o, (np.floating,)):\n",
    "        return float(o)\n",
    "    if isinstance(o, np.ndarray):\n",
    "        return o.tolist()\n",
    "    raise TypeError(f\"Type {type(o)} not serializable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15a5af4-85ea-4f03-98ab-6abf00b11802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT_EMB_768 : /root/Invertebrates_EC50_multi_fusion/SMILES/smiles_outputs/reg_smiles_cls_embeddings_all.npy\n",
      "PHY_EMB_PATH : /root/Invertebrates_EC50_multi_fusion/phychem/physchem_mlp_rf_v2/emb_physchem_mlp_all.npy\n",
      "DATA_PATH    : /root/fusion_dataset/with_physchem_excels/Invertebrates_EC50_unique_physchem.xlsx\n",
      "OUT_DIR_TP   : /root/Invertebrates_EC50_multi_fusion/early(T+P)/text_plus_physchem_simple\n"
     ]
    }
   ],
   "source": [
    "# ===== Notebook 1 – Cell 2: 路径 & 超参数网格 =====\n",
    "\n",
    "ROOT_MULTI = Path(\"/root/Invertebrates_EC50_multi_fusion\")\n",
    "\n",
    "# 文本 CLS 全量嵌入（与 df 行号对齐）\n",
    "TEXT_DIR      = ROOT_MULTI / \"SMILES\" / \"smiles_outputs\"\n",
    "TEXT_EMB_768  = TEXT_DIR / \"reg_smiles_cls_embeddings_all.npy\"\n",
    "\n",
    "# 理化性质 MLP embedding（descMLP 输出）\n",
    "PHY_DIR        = ROOT_MULTI / \"phychem\" / \"physchem_mlp_rf_v2\"\n",
    "PHY_EMB_PATH   = PHY_DIR / \"emb_physchem_mlp_all.npy\"\n",
    "PHY_ROWID_PATH = PHY_DIR / \"row_id_clean.npy\"\n",
    "\n",
    "# 原始表（带 SMILES / mgperL / Duration / Effect / Endpoint / desc）\n",
    "DATA_PATH = Path(\"/root/fusion_dataset/with_physchem_excels/Invertebrates_EC50_unique_physchem.xlsx\")\n",
    "\n",
    "# 输出目录：Text + PhysChem 早期融合（简化版）\n",
    "FUSION_ROOT_TP = ROOT_MULTI / \"early(T+P)\"\n",
    "OUT_DIR_TP     = FUSION_ROOT_TP / \"text_plus_physchem_simple\"\n",
    "MODELS_DIR_TP  = OUT_DIR_TP / \"models\"\n",
    "\n",
    "for d in [FUSION_ROOT_TP, OUT_DIR_TP, MODELS_DIR_TP]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 列名（按你的 excel 调整）\n",
    "SMILES_COL   = \"SMILES_Canonical_RDKit\"\n",
    "EFFECT_COL   = \"Effect\"\n",
    "ENDPOINT_COL = \"Endpoint\"\n",
    "DURATION_COL = \"Duration_Value(hour)\"   # 如果不一样就改\n",
    "LABEL_RAW    = \"mgperL\"\n",
    "LABEL_LOG    = \"mgperL_log\"             # 我们统一在 log10(mg/L) 空间上训练\n",
    "LABEL_COL    = LABEL_LOG\n",
    "\n",
    "TEXT_DIM_TARGET = 256  # 768 -> 256\n",
    "\n",
    "# RF 随机搜索空间（直接用 RandomizedSearchCV）\n",
    "param_distributions_rf = {\n",
    "    \"n_estimators\":      [200, 300, 500, 800, 1000],\n",
    "    \"max_depth\":         [None, 10, 20, 30, 40],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\":  [1, 2, 4],\n",
    "    \"max_features\":      [\"sqrt\", \"log2\", 0.3, 0.5, 0.8],\n",
    "}\n",
    "\n",
    "print(\"TEXT_EMB_768 :\", TEXT_EMB_768)\n",
    "print(\"PHY_EMB_PATH :\", PHY_EMB_PATH)\n",
    "print(\"DATA_PATH    :\", DATA_PATH)\n",
    "print(\"OUT_DIR_TP   :\", OUT_DIR_TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e249c7-6f7c-46c9-b6bd-bd21bfb7ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede8c20b-f94e-40fb-83b0-5a30f661f6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df 形状: (3620, 36)\n",
      "   row_id    SMILES_Canonical_RDKit  mgperL  mgperL_log  Duration_Value(hour)  \\\n",
      "0       0        [Cl-].[Cl-].[Zn+2]     1.3    0.113943                  96.0   \n",
      "1       1  O=S(=O)([O-])[O-].[Zn+2]     2.5    0.397940                  24.0   \n",
      "2       2        [Cl-].[Cl-].[Pb+2]    40.8    1.610660                  96.0   \n",
      "3       3  O=S(=O)([O-])[O-].[Cu+2]     1.9    0.278754                  24.0   \n",
      "4       4  O=S(=O)([O-])[O-].[Cu+2]     0.6   -0.221849                  96.0   \n",
      "\n",
      "  Effect Endpoint  \n",
      "0    ITX     EC50  \n",
      "1    ITX     EC50  \n",
      "2    ITX     EC50  \n",
      "3    ITX     EC50  \n",
      "4    ITX     EC50  \n"
     ]
    }
   ],
   "source": [
    "# ===== Notebook 1 – Cell 3: 读取 df & 生成 mgperL_log =====\n",
    "\n",
    "df = pd.read_excel(DATA_PATH, engine=\"openpyxl\")\n",
    "\n",
    "if \"row_id\" not in df.columns:\n",
    "    df = df.reset_index().rename(columns={\"index\": \"row_id\"})\n",
    "df[\"row_id\"] = df[\"row_id\"].astype(int)\n",
    "\n",
    "# 标签：若没有 mgperL_log，则由 mgperL 生成\n",
    "if LABEL_LOG not in df.columns:\n",
    "    df[LABEL_RAW] = pd.to_numeric(df[LABEL_RAW], errors=\"coerce\")\n",
    "    mask_valid = df[LABEL_RAW] > 0\n",
    "    df[LABEL_LOG] = np.where(mask_valid, np.log10(df[LABEL_RAW]), np.nan)\n",
    "\n",
    "print(\"df 形状:\", df.shape)\n",
    "print(df[[\"row_id\", SMILES_COL, LABEL_RAW, LABEL_LOG, DURATION_COL, EFFECT_COL, ENDPOINT_COL]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e76c9-f2eb-4647-af27-ab73a92e312a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5878db5f-9e9d-4793-89e7-9e028ba1a76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_all 形状: (3620, 768)\n",
      "phys_emb 形状: (3406, 64)\n",
      "rowid_phys 范围: 0 → 3619\n",
      "Text+PhysChem 对齐后样本数: 3406\n",
      "text_tp 形状: (3406, 768)\n",
      "phys_tp 形状: (3406, 64)\n",
      "初始样本数: 3406\n",
      "保留样本数: 3406\n",
      "过滤后 text_tp 形状: (3406, 768)\n",
      "过滤后 phys_tp 形状: (3406, 64)\n",
      "过滤后 y_tp 形状: (3406,)\n",
      "cat_tp 形状: (3406, 3)\n",
      "dur_tp 形状: (3406, 1)\n",
      "样本总数: 3406\n"
     ]
    }
   ],
   "source": [
    "# ===== Notebook 1 – Cell 4: 加载 Text & PhysChem embedding，对齐构造特征 =====\n",
    "\n",
    "# 1) 文本 CLS 全量嵌入（按 df 行号顺序）\n",
    "text_all = np.load(TEXT_EMB_768)\n",
    "assert text_all.shape[0] == len(df), \"text_all 行数与 df 不一致，请检查。\"\n",
    "print(\"text_all 形状:\", text_all.shape)\n",
    "\n",
    "# 2) 理化性质 MLP embedding + row_id\n",
    "phys_emb   = np.load(PHY_EMB_PATH)                   # (N_phys, d_phys)\n",
    "rowid_phys = np.load(PHY_ROWID_PATH).astype(int)     # (N_phys,)\n",
    "print(\"phys_emb 形状:\", phys_emb.shape)\n",
    "print(\"rowid_phys 范围:\", rowid_phys.min(), \"→\", rowid_phys.max())\n",
    "\n",
    "# 3) 对齐 Text+PhysChem 子集：按 rowid_phys 从 df / text_all 取子集\n",
    "df_indexed = df.set_index(\"row_id\")\n",
    "\n",
    "meta_tp_list  = []\n",
    "text_tp_list  = []\n",
    "phys_tp_list  = []\n",
    "y_tp_list     = []\n",
    "rowid_tp_list = []\n",
    "\n",
    "for rid, p_vec in zip(rowid_phys, phys_emb):\n",
    "    if rid not in df_indexed.index:\n",
    "        continue\n",
    "    row_meta = df_indexed.loc[rid]\n",
    "    if pd.isna(row_meta[LABEL_COL]) or not np.isfinite(row_meta[LABEL_COL]):\n",
    "        continue\n",
    "\n",
    "    meta_tp_list.append(row_meta)\n",
    "    text_tp_list.append(text_all[rid])\n",
    "    phys_tp_list.append(p_vec)\n",
    "    y_tp_list.append(row_meta[LABEL_COL])\n",
    "    rowid_tp_list.append(rid)\n",
    "\n",
    "meta_tp  = pd.DataFrame(meta_tp_list).reset_index(drop=True)\n",
    "text_tp  = np.stack(text_tp_list, axis=0)\n",
    "phys_tp  = np.stack(phys_tp_list, axis=0)\n",
    "y_tp     = np.array(y_tp_list, dtype=float)\n",
    "rowid_tp = np.array(rowid_tp_list, dtype=int)\n",
    "\n",
    "print(\"Text+PhysChem 对齐后样本数:\", len(y_tp))\n",
    "print(\"text_tp 形状:\", text_tp.shape)\n",
    "print(\"phys_tp 形状:\", phys_tp.shape)\n",
    "\n",
    "# 4) 过滤 Duration / Effect / Endpoint 缺失\n",
    "mask_keep = (\n",
    "    meta_tp[DURATION_COL].notna()\n",
    "    & meta_tp[EFFECT_COL].notna()\n",
    "    & meta_tp[ENDPOINT_COL].notna()\n",
    ")\n",
    "\n",
    "print(\"初始样本数:\", len(meta_tp))\n",
    "print(\"保留样本数:\", int(mask_keep.sum()))\n",
    "\n",
    "meta_tp  = meta_tp.loc[mask_keep].reset_index(drop=True)\n",
    "text_tp  = text_tp[mask_keep.values]\n",
    "phys_tp  = phys_tp[mask_keep.values]\n",
    "y_tp     = y_tp[mask_keep.values]\n",
    "rowid_tp = rowid_tp[mask_keep.values]\n",
    "\n",
    "print(\"过滤后 text_tp 形状:\", text_tp.shape)\n",
    "print(\"过滤后 phys_tp 形状:\", phys_tp.shape)\n",
    "print(\"过滤后 y_tp 形状:\", y_tp.shape)\n",
    "\n",
    "# 5) One-hot: Effect + Endpoint（在整个 Text+PhysChem 子集上做一次，保证列一致）\n",
    "cat_cols = [EFFECT_COL, ENDPOINT_COL]\n",
    "cat_dummies_tp = pd.get_dummies(meta_tp[cat_cols], dummy_na=False)\n",
    "cat_tp = cat_dummies_tp.values.astype(float)\n",
    "cat_feature_names_tp = list(cat_dummies_tp.columns)\n",
    "\n",
    "# 6) Duration 数值特征\n",
    "meta_tp[DURATION_COL] = pd.to_numeric(meta_tp[DURATION_COL], errors=\"coerce\")\n",
    "dur_median = meta_tp[DURATION_COL].median()\n",
    "meta_tp[DURATION_COL] = meta_tp[DURATION_COL].fillna(dur_median)\n",
    "dur_tp = meta_tp[[DURATION_COL]].values.astype(float)\n",
    "numeric_feature_names_tp = [DURATION_COL]\n",
    "\n",
    "# 7) 分组用 SMILES\n",
    "groups_tp = meta_tp[SMILES_COL].astype(str).values\n",
    "\n",
    "print(\"cat_tp 形状:\", cat_tp.shape)\n",
    "print(\"dur_tp 形状:\", dur_tp.shape)\n",
    "print(\"样本总数:\", len(y_tp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939c7b2-a49c-435b-ab9c-e4094074d3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f2f0da-939b-43cc-bb22-9327a4c00056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text+PhysChem train 样本数: 2716\n",
      "Text+PhysChem test  样本数: 690\n",
      "text_train_256 形状: (2716, 256)\n",
      "X_train_tp 形状: (2716, 324)\n",
      "X_test_tp  形状: (690, 324)\n"
     ]
    }
   ],
   "source": [
    "# ===== Notebook 1 – Cell 5: 8:2 划分 + 在 train80% 上构造最终特征 =====\n",
    "\n",
    "N_tp = len(y_tp)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8, random_state=2025)\n",
    "\n",
    "train_idx_tp, test_idx_tp = next(\n",
    "    gss.split(np.zeros(N_tp), y_tp, groups=groups_tp)\n",
    ")\n",
    "\n",
    "train_idx_tp = np.array(train_idx_tp, dtype=np.int64)\n",
    "test_idx_tp  = np.array(test_idx_tp, dtype=np.int64)\n",
    "\n",
    "print(\"Text+PhysChem train 样本数:\", len(train_idx_tp))\n",
    "print(\"Text+PhysChem test  样本数:\", len(test_idx_tp))\n",
    "\n",
    "# 保存索引和 row_id，方便以后可视化或 AD\n",
    "np.save(OUT_DIR_TP / \"train_idx_tp.npy\", train_idx_tp)\n",
    "np.save(OUT_DIR_TP / \"test_idx_tp.npy\",  test_idx_tp)\n",
    "np.save(OUT_DIR_TP / \"row_id_train_tp.npy\", rowid_tp[train_idx_tp])\n",
    "np.save(OUT_DIR_TP / \"row_id_test_tp.npy\",  rowid_tp[test_idx_tp])\n",
    "\n",
    "# ========= 只在 train80% 上拟合 scaler & SVD =========\n",
    "text_train_raw = text_tp[train_idx_tp]   # (N_train, 768)\n",
    "text_test_raw  = text_tp[test_idx_tp]\n",
    "\n",
    "phys_train_raw = phys_tp[train_idx_tp]\n",
    "phys_test_raw  = phys_tp[test_idx_tp]\n",
    "\n",
    "dur_train_raw = dur_tp[train_idx_tp]\n",
    "dur_test_raw  = dur_tp[test_idx_tp]\n",
    "\n",
    "cat_train = cat_tp[train_idx_tp]\n",
    "cat_test  = cat_tp[test_idx_tp]\n",
    "\n",
    "y_train_tp = y_tp[train_idx_tp]\n",
    "y_test_tp  = y_tp[test_idx_tp]\n",
    "groups_train_tp = groups_tp[train_idx_tp]\n",
    "\n",
    "# 1) 标准化\n",
    "scaler_text = StandardScaler().fit(text_train_raw)\n",
    "scaler_phys = StandardScaler().fit(phys_train_raw)\n",
    "scaler_dur  = StandardScaler().fit(dur_train_raw)\n",
    "\n",
    "text_train_std = scaler_text.transform(text_train_raw)\n",
    "text_test_std  = scaler_text.transform(text_test_raw)\n",
    "\n",
    "phys_train_std = scaler_phys.transform(phys_train_raw)\n",
    "phys_test_std  = scaler_phys.transform(phys_test_raw)\n",
    "\n",
    "dur_train_std  = scaler_dur.transform(dur_train_raw)\n",
    "dur_test_std   = scaler_dur.transform(dur_test_raw)\n",
    "\n",
    "# 2) 文本 SVD: 768 -> 256（只在 train80% 上拟合）\n",
    "svd_text = TruncatedSVD(\n",
    "    n_components=TEXT_DIM_TARGET,\n",
    "    random_state=GLOBAL_SEED\n",
    ")\n",
    "text_train_256 = svd_text.fit_transform(text_train_std)\n",
    "text_test_256  = svd_text.transform(text_test_std)\n",
    "\n",
    "print(\"text_train_256 形状:\", text_train_256.shape)\n",
    "\n",
    "# 3) 拼接最终特征：[text_256, phys_std, dur_std, onehot]\n",
    "X_train_tp = np.concatenate(\n",
    "    [text_train_256, phys_train_std, dur_train_std, cat_train], axis=1\n",
    ")\n",
    "X_test_tp = np.concatenate(\n",
    "    [text_test_256, phys_test_std, dur_test_std, cat_test], axis=1\n",
    ")\n",
    "\n",
    "print(\"X_train_tp 形状:\", X_train_tp.shape)\n",
    "print(\"X_test_tp  形状:\", X_test_tp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97667a-0fb8-4909-95aa-681c72e7b8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff85ea1-ae31-4e15-82ce-4ec74ca41e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all_tp 形状: (3406, 324)\n",
      "✅ Text+PhysChem 早期融合 embeddings 已保存到: /root/Invertebrates_EC50_multi_fusion/early(T+P)/text_plus_physchem_simple\n"
     ]
    }
   ],
   "source": [
    "# ===== Text+PhysChem: 保存早期融合后的 embeddings =====\n",
    "\n",
    "# 1) 用 train80% 拟合好的 scaler/SVD，对“所有样本” transform 一遍\n",
    "text_all_std_tp = scaler_text.transform(text_tp)\n",
    "phys_all_std_tp = scaler_phys.transform(phys_tp)\n",
    "dur_all_std_tp  = scaler_dur.transform(dur_tp)\n",
    "\n",
    "text_all_256_tp = svd_text.transform(text_all_std_tp)  # (N_all, 256)\n",
    "\n",
    "# 2) 全体样本拼接：[text_256, phys_std, dur_std, onehot]\n",
    "X_all_tp = np.concatenate(\n",
    "    [text_all_256_tp, phys_all_std_tp, dur_all_std_tp, cat_tp],\n",
    "    axis=1\n",
    ")\n",
    "print(\"X_all_tp 形状:\", X_all_tp.shape)\n",
    "\n",
    "# 3) 保存 train/test 特征和全体 fused embedding\n",
    "np.save(OUT_DIR_TP / \"X_train_tp.npy\", X_train_tp)\n",
    "np.save(OUT_DIR_TP / \"X_test_tp.npy\",  X_test_tp)\n",
    "np.save(OUT_DIR_TP / \"y_train_tp.npy\", y_train_tp)\n",
    "np.save(OUT_DIR_TP / \"y_test_tp.npy\",  y_test_tp)\n",
    "\n",
    "np.save(OUT_DIR_TP / \"X_all_tp_fused.npy\", X_all_tp)\n",
    "np.save(OUT_DIR_TP / \"row_id_all_tp.npy\",  rowid_tp)\n",
    "\n",
    "print(\"✅ Text+PhysChem 早期融合 embeddings 已保存到:\", OUT_DIR_TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cd538-122b-4fdc-ba77-eafa5444b51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2186e70-0315-44d2-a891-dbf4b183d176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始在 train80% 上用十折 GroupKFold 调参 RF ...\n",
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=52.8min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=16.3min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=16.5min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 7.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.7min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=21.0min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=30.5min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=25.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 5.9min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=52.2min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=15.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=17.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 7.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.7min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  58.2s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 2.7min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  43.3s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  41.6s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=11.8min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=21.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.8min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 6.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 7.9min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=13.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 6.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 6.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.2min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=39.3min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=38.4min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=29.8min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=20.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=12.4min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.5min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=23.8min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.9min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=51.1min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.7min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=18.0min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.0min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 7.9min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 7.2min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=  56.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.0min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  47.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  51.9s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=12.1min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.5min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=32.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.1min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=25.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.3min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=40.9min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.6min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.6min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.5min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=16.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=29.5min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=20.0min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.9min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 6.9min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.0min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.6min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=14.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.0min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 6.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.5min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=39.3min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.9min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.9min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.2min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=16.0min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=29.5min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=13.0min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=31.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=24.4min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.3min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=52.5min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=15.8min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=30.9min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=20.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.5min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.2min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=15.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.0min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=25.0min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.0min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=38.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=39.0min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  51.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  49.6s\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 8.8min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 7.9min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 2.9min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  43.4s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  43.6s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=11.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 2.7min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.0min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=31.2min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.1min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=24.6min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.9min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=52.8min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.7min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=16.5min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  44.1s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  46.4s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  50.5s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  48.0s\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 8.4min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.3min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.3min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.7min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  43.6s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=11.9min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=21.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.4min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 6.9min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.9min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.4min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=24.9min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.3min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 5.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=53.3min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=15.9min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=30.8min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=21.0min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=31.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=14.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.0min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.2min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=51.1min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.8min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=17.8min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  58.2s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  46.3s\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  48.9s\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 8.4min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.5min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.5min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.7min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=22.7min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.7min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.2min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 6.6min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.0min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=13.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 6.6min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 5.9min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 6.2min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=41.0min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.9min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=16.2min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.9min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.4min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=29.6min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=12.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=31.0min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=15.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=25.3min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.9min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=13.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=52.3min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=16.1min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=17.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 7.6min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.4min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.1min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  53.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  38.7s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=11.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.4min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=30.7min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=15.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=13.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=12.8min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.3min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=40.4min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.7min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.2min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 8.5min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.7min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.6min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=17.2min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=28.4min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=20.0min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=12.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.8min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=15.7min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=24.5min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.0min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.1min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=40.5min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.2min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 4.6min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.6min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=16.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=30.3min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=12.0min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.5min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=32.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=15.3min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=800; total time=24.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 3.8min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.1min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=2, min_samples_split=5, n_estimators=800; total time=41.0min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time= 3.7min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.2min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=16.0min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.8min\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time= 1.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=30.3min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=12.4min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.1min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=33.1min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=15.9min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=13.8min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=13.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.2min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=49.8min\n",
      "[CV] END max_depth=None, max_features=0.5, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 7.4min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 2.0min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=500; total time= 1.9min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=16.7min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time=29.7min\n",
      "[CV] END max_depth=None, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=500; total time=20.2min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=800; total time=11.4min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.2min\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 7.2min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.3min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time= 8.1min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=14.0min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 7.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1000; total time= 4.1min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=14.5min\n",
      "[CV] END max_depth=40, max_features=0.8, min_samples_leaf=1, min_samples_split=5, n_estimators=1000; total time=52.9min\n",
      "[CV] END max_depth=40, max_features=0.3, min_samples_leaf=2, min_samples_split=10, n_estimators=800; total time=15.2min\n",
      "[CV] END max_depth=30, max_features=0.5, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=17.2min\n",
      "[CV] END max_depth=10, max_features=0.8, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time= 7.8min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=800; total time= 2.8min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.0min\n",
      "[CV] END max_depth=40, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time= 1.2min\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  46.7s\n",
      "[CV] END max_depth=10, max_features=0.5, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=11.9min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.0min\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=1000; total time= 3.3min\n",
      "[CV] END max_depth=20, max_features=0.8, min_samples_leaf=1, min_samples_split=10, n_estimators=800; total time=31.2min\n",
      "[CV] END max_depth=30, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=800; total time=16.6min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time=13.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 6.4min\n",
      "[CV] END max_depth=10, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 6.5min\n",
      "[CV] END max_depth=None, max_features=0.3, min_samples_leaf=2, min_samples_split=2, n_estimators=1000; total time=15.0min\n",
      "\n",
      "Text+PhysChem 最优超参 (基于 train80% 十折CV):\n",
      "{'n_estimators': 800, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 0.8, 'max_depth': 40}\n",
      "最优CV分数 (neg MAE): -0.5495085068968303\n",
      "\n",
      "===== Text+PhysChem 最终 RF：train(80%) 指标 =====\n",
      "MAE: 0.2532\n",
      "RMSE: 0.3705\n",
      "R2: 0.9023\n",
      "Pearson_r: 0.9542\n",
      "\n",
      "===== Text+PhysChem 最终 RF：独立 test(20%) 指标 =====\n",
      "MAE: 0.6006\n",
      "RMSE: 0.8238\n",
      "R2: 0.5508\n",
      "Pearson_r: 0.7472\n",
      "\n",
      "✅ Text+PhysChem 最终模型 & 指标已保存：\n",
      "   模型路径: /root/Invertebrates_EC50_multi_fusion/early(T+P)/text_plus_physchem_simple/rf_text_phys_8_2_final_simple.joblib\n",
      "   指标路径: /root/Invertebrates_EC50_multi_fusion/early(T+P)/text_plus_physchem_simple/metrics_text_phys_rf_8_2_simple.json\n"
     ]
    }
   ],
   "source": [
    "# ===== Notebook 1 – Cell 6: 十折 GroupKFold 调参 + 最终模型 & test 评估 =====\n",
    "\n",
    "# 1) 定义 RF 基模型\n",
    "rf_base = RandomForestRegressor(\n",
    "    random_state=GLOBAL_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 2) 十折 GroupKFold（只在 train80% 内）\n",
    "cv_tp = GroupKFold(n_splits=10)\n",
    "\n",
    "# 3) RandomizedSearchCV：以 neg MAE 作为优化目标（越大越好）\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=param_distributions_rf,\n",
    "    n_iter=30,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=cv_tp,\n",
    "    n_jobs=-1,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "print(\"开始在 train80% 上用十折 GroupKFold 调参 RF ...\")\n",
    "rf_search.fit(X_train_tp, y_train_tp, groups=groups_train_tp)\n",
    "\n",
    "best_params_tp = rf_search.best_params_\n",
    "best_score_tp  = rf_search.best_score_\n",
    "print(\"\\nText+PhysChem 最优超参 (基于 train80% 十折CV):\")\n",
    "print(best_params_tp)\n",
    "print(\"最优CV分数 (neg MAE):\", best_score_tp)\n",
    "\n",
    "# 4) 用最优超参在整个 train80% 上重训一个最终模型\n",
    "rf_final_tp = RandomForestRegressor(\n",
    "    **best_params_tp,\n",
    "    random_state=GLOBAL_SEED,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf_final_tp.fit(X_train_tp, y_train_tp)\n",
    "\n",
    "# 5) 在 train80% 和 test20% 上预测与评估\n",
    "y_train_pred_tp = rf_final_tp.predict(X_train_tp)\n",
    "y_test_pred_tp  = rf_final_tp.predict(X_test_tp)\n",
    "\n",
    "metrics_train_tp = compute_regression_metrics(y_train_tp, y_train_pred_tp)\n",
    "metrics_test_tp  = compute_regression_metrics(y_test_tp,  y_test_pred_tp)\n",
    "\n",
    "print(\"\\n===== Text+PhysChem 最终 RF：train(80%) 指标 =====\")\n",
    "for k, v in metrics_train_tp.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n===== Text+PhysChem 最终 RF：独立 test(20%) 指标 =====\")\n",
    "for k, v in metrics_test_tp.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# 6) 保存模型、变换器、预测结果和指标\n",
    "FINAL_MODEL_TP_PATH   = OUT_DIR_TP / \"rf_text_phys_8_2_final_simple.joblib\"\n",
    "METRICS_TP_JSON_PATH  = OUT_DIR_TP / \"metrics_text_phys_rf_8_2_simple.json\"\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"model\": rf_final_tp,\n",
    "        \"scaler_text\": scaler_text,\n",
    "        \"svd_text\": svd_text,\n",
    "        \"scaler_phys\": scaler_phys,\n",
    "        \"scaler_dur\": scaler_dur,\n",
    "        \"cat_feature_names\": cat_feature_names_tp,\n",
    "        \"numeric_feature_names\": numeric_feature_names_tp,\n",
    "        \"config\": {\n",
    "            \"TEXT_DIM_TARGET\": TEXT_DIM_TARGET,\n",
    "            \"GLOBAL_SEED\": int(GLOBAL_SEED),\n",
    "            \"param_distributions\": param_distributions_rf,\n",
    "        },\n",
    "    },\n",
    "    FINAL_MODEL_TP_PATH\n",
    ")\n",
    "\n",
    "np.save(OUT_DIR_TP / \"y_train_tp.npy\",        y_train_tp)\n",
    "np.save(OUT_DIR_TP / \"y_train_pred_tp.npy\",   y_train_pred_tp)\n",
    "np.save(OUT_DIR_TP / \"y_test_tp.npy\",         y_test_tp)\n",
    "np.save(OUT_DIR_TP / \"y_test_pred_tp.npy\",    y_test_pred_tp)\n",
    "\n",
    "with open(METRICS_TP_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"best_params_cv\": best_params_tp,\n",
    "            \"best_score_cv_neg_mae\": float(best_score_tp),\n",
    "            \"train_metrics\": metrics_train_tp,\n",
    "            \"test_metrics\": metrics_test_tp,\n",
    "            \"n_total\": int(len(y_tp)),\n",
    "            \"n_train\": int(len(y_train_tp)),\n",
    "            \"n_test\": int(len(y_test_tp)),\n",
    "        },\n",
    "        f,\n",
    "        ensure_ascii=False,\n",
    "        indent=2,\n",
    "        default=np_encoder,\n",
    "    )\n",
    "\n",
    "print(\"\\n✅ Text+PhysChem 最终模型 & 指标已保存：\")\n",
    "print(\"   模型路径:\", FINAL_MODEL_TP_PATH)\n",
    "print(\"   指标路径:\", METRICS_TP_JSON_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7d7e9-b8b4-4514-b61f-20c311b25ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
